{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Импортируем библиотеки и загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:/Users/User/API/2.csv',sep=';',encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>periodid</th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>disc</th>\n",
       "      <th>isGk</th>\n",
       "      <th>isShared</th>\n",
       "      <th>isUsn</th>\n",
       "      <th>isEnvd</th>\n",
       "      <th>isBudget</th>\n",
       "      <th>...</th>\n",
       "      <th>mainSystem1420</th>\n",
       "      <th>mainSystem1421</th>\n",
       "      <th>mainSystem1422</th>\n",
       "      <th>mainSystem1423</th>\n",
       "      <th>mainSystem1424</th>\n",
       "      <th>mainSystem1425</th>\n",
       "      <th>mainSystem1426</th>\n",
       "      <th>mainSystem1427</th>\n",
       "      <th>mainSystem1428</th>\n",
       "      <th>notMainSystem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>20861</td>\n",
       "      <td>01.04.2017 0:00</td>\n",
       "      <td>30.04.2017 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>20862</td>\n",
       "      <td>01.05.2017 0:00</td>\n",
       "      <td>31.05.2017 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20864</td>\n",
       "      <td>01.06.2017 0:00</td>\n",
       "      <td>30.06.2017 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20865</td>\n",
       "      <td>01.07.2017 0:00</td>\n",
       "      <td>31.07.2017 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>20866</td>\n",
       "      <td>01.08.2017 0:00</td>\n",
       "      <td>31.08.2017 0:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  periodid        startdate          enddate  disc  isGk  isShared  \\\n",
       "0   3     20861  01.04.2017 0:00  30.04.2017 0:00     0     0         0   \n",
       "1   3     20862  01.05.2017 0:00  31.05.2017 0:00     0     0         0   \n",
       "2   3     20864  01.06.2017 0:00  30.06.2017 0:00     0     0         0   \n",
       "3   3     20865  01.07.2017 0:00  31.07.2017 0:00     0     0         0   \n",
       "4   3     20866  01.08.2017 0:00  31.08.2017 0:00     0     0         0   \n",
       "\n",
       "   isUsn  isEnvd  isBudget  ...  mainSystem1420  mainSystem1421  \\\n",
       "0      0       0         0  ...               0               0   \n",
       "1      0       0         0  ...               0               0   \n",
       "2      0       0         0  ...               0               0   \n",
       "3      0       0         0  ...               0               0   \n",
       "4      0       0         0  ...               0               0   \n",
       "\n",
       "   mainSystem1422  mainSystem1423  mainSystem1424  mainSystem1425  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   mainSystem1426  mainSystem1427  mainSystem1428  notMainSystem  \n",
       "0               0               0               0              1  \n",
       "1               0               0               0              1  \n",
       "2               0               0               0              1  \n",
       "3               0               0               0              1  \n",
       "4               0               0               0              1  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4260"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      3,      29,      42, ..., 1696323, 1696385, 1696463],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_id=df.id.unique()\n",
    "unique_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['enddate'] = pd.to_datetime(df.enddate, format='%d.%m.%Y %H:%M')\n",
    "df['startdate']= pd.to_datetime(df.startdate, format='%d.%m.%Y %H:%M')\n",
    "df['paid_time']= (pd.to_datetime(df.paidDate, format='%d.%m.%Y %H:%M')-df.startdate).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_data=df.groupby('id',as_index=False).agg({'startdate':'max'}).rename({'startdate':'last_month'},axis=1)\n",
    "df['last_month']=df.groupby(['id'])['startdate'].transform(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2017-12-01\n",
       "1        2017-12-01\n",
       "2        2017-12-01\n",
       "3        2017-12-01\n",
       "4        2017-12-01\n",
       "            ...    \n",
       "102451   2019-11-01\n",
       "102452   2019-11-01\n",
       "102453   2019-11-01\n",
       "102454   2019-11-01\n",
       "102455   2019-11-01\n",
       "Name: last_month, Length: 102456, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          NaN\n",
       "1          NaN\n",
       "2          NaN\n",
       "3          NaN\n",
       "4          NaN\n",
       "          ... \n",
       "102451     NaN\n",
       "102452     3.0\n",
       "102453    10.0\n",
       "102454    34.0\n",
       "102455   -15.0\n",
       "Name: paid_time, Length: 102456, dtype: float64"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.paid_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_data['is_gone']=(client_data.last_month!='2019-11-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>last_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_gone</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>2834</td>\n",
       "      <td>2834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1426</td>\n",
       "      <td>1426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  last_month\n",
       "is_gone                  \n",
       "False    2834        2834\n",
       "True     1426        1426"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_data.groupby('is_gone').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>last_month</th>\n",
       "      <th>is_gone</th>\n",
       "      <th>mainSystem1425max</th>\n",
       "      <th>mainSystem1425min</th>\n",
       "      <th>mainSystem1425cur</th>\n",
       "      <th>mainSystem1418max</th>\n",
       "      <th>mainSystem1418min</th>\n",
       "      <th>mainSystem1418cur</th>\n",
       "      <th>mainSystem1409max</th>\n",
       "      <th>...</th>\n",
       "      <th>incidentReccur</th>\n",
       "      <th>isNssmax</th>\n",
       "      <th>isNssmin</th>\n",
       "      <th>isNsscur</th>\n",
       "      <th>mainSystem1419max</th>\n",
       "      <th>mainSystem1419min</th>\n",
       "      <th>mainSystem1419cur</th>\n",
       "      <th>monthServiceSummax</th>\n",
       "      <th>monthServiceSummin</th>\n",
       "      <th>monthServiceSumcur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32752.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.017027</td>\n",
       "      <td>35063.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24700.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>102</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016086</td>\n",
       "      <td>12646.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>108</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.016113</td>\n",
       "      <td>3983.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>123</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18730.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>128</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>132</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.387566</td>\n",
       "      <td>10289.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>137</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15437.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>185</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>211</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>246</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.032993</td>\n",
       "      <td>7076.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>251</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.039846</td>\n",
       "      <td>6209.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>319</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>338</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>342</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>361</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7186.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>447</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13406.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>535</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>538</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8310.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>555</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16033.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>557</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.038161</td>\n",
       "      <td>61566.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>589</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22695.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>612</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40773.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>640</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>710</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>711</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>712</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14406.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id last_month  is_gone  mainSystem1425max  mainSystem1425min  \\\n",
       "0     3 2017-12-01     True                1.0                1.0   \n",
       "1    29 2019-11-01    False                1.0                1.0   \n",
       "2    42 2019-11-01    False                1.0                1.0   \n",
       "3    63 2019-11-01    False                1.0                1.0   \n",
       "4    65 2019-11-01    False                1.0                1.0   \n",
       "5   102 2019-11-01    False                1.0                1.0   \n",
       "6   108 2019-11-01    False                1.0                1.0   \n",
       "7   123 2019-11-01    False                1.0                1.0   \n",
       "8   128 2019-11-01    False                1.0                1.0   \n",
       "9   132 2019-11-01    False                1.0                1.0   \n",
       "10  137 2019-11-01    False                1.0                1.0   \n",
       "11  185 2019-11-01    False                1.0                1.0   \n",
       "12  211 2018-09-01     True                1.0                1.0   \n",
       "13  246 2019-11-01    False                1.0                1.0   \n",
       "14  251 2019-11-01    False                1.0                1.0   \n",
       "15  319 2017-12-01     True                1.0                1.0   \n",
       "16  338 2019-11-01    False                1.0                1.0   \n",
       "17  342 2019-08-01     True                1.0                1.0   \n",
       "18  361 2019-11-01    False                1.0                1.0   \n",
       "19  447 2019-11-01    False                1.0                1.0   \n",
       "20  535 2017-12-01     True                1.0                1.0   \n",
       "21  538 2019-11-01    False                1.0                1.0   \n",
       "22  555 2019-11-01    False                1.0                1.0   \n",
       "23  557 2019-11-01    False                1.0                1.0   \n",
       "24  589 2019-11-01    False                1.0                1.0   \n",
       "25  612 2019-11-01    False                1.0                1.0   \n",
       "26  640 2019-11-01    False                1.0                1.0   \n",
       "27  710 2019-11-01    False                1.0                1.0   \n",
       "28  711 2019-11-01    False                1.0                1.0   \n",
       "29  712 2019-11-01    False                1.0                1.0   \n",
       "\n",
       "    mainSystem1425cur  mainSystem1418max  mainSystem1418min  \\\n",
       "0                 0.0                1.0                1.0   \n",
       "1                 0.0                1.0                1.0   \n",
       "2                 0.0                1.0                1.0   \n",
       "3                 0.0                1.0                1.0   \n",
       "4                 0.0                1.0                1.0   \n",
       "5                 0.0                1.0                1.0   \n",
       "6                 0.0                1.0                1.0   \n",
       "7                 0.0                1.0                1.0   \n",
       "8                 0.0                1.0                1.0   \n",
       "9                 0.0                1.0                1.0   \n",
       "10                1.0                1.0                1.0   \n",
       "11                0.0                1.0                1.0   \n",
       "12                0.0                1.0                1.0   \n",
       "13                0.0                1.0                1.0   \n",
       "14                0.0                1.0                1.0   \n",
       "15                0.0                1.0                1.0   \n",
       "16                0.0                1.0                1.0   \n",
       "17                0.0                1.0                1.0   \n",
       "18                0.0                1.0                1.0   \n",
       "19                1.0                1.0                1.0   \n",
       "20                0.0                1.0                1.0   \n",
       "21                0.0                1.0                1.0   \n",
       "22                0.0                1.0                1.0   \n",
       "23                0.0                1.0                1.0   \n",
       "24                0.0                1.0                1.0   \n",
       "25                0.0                1.0                1.0   \n",
       "26                0.0                1.0                1.0   \n",
       "27                0.0                1.0                1.0   \n",
       "28                0.0                1.0                1.0   \n",
       "29                0.0                1.0                1.0   \n",
       "\n",
       "    mainSystem1418cur  mainSystem1409max  ...  incidentReccur  isNssmax  \\\n",
       "0                 0.0                1.0  ...             0.0       NaN   \n",
       "1                 0.0                1.0  ...             0.0       1.0   \n",
       "2                 0.0                1.0  ...             0.0       1.0   \n",
       "3                 0.0                1.0  ...             0.0       1.0   \n",
       "4                 0.0                1.0  ...             0.0       1.0   \n",
       "5                 0.0                1.0  ...             0.0       1.0   \n",
       "6                 1.0                1.0  ...             0.0       1.0   \n",
       "7                 0.0                1.0  ...             0.0       1.0   \n",
       "8                 0.0                1.0  ...             0.0       1.0   \n",
       "9                 0.0                1.0  ...             0.0       1.0   \n",
       "10                0.0                1.0  ...             0.0       1.0   \n",
       "11                0.0                1.0  ...             0.0       1.0   \n",
       "12                0.0                1.0  ...             0.0       NaN   \n",
       "13                0.0                1.0  ...             0.0       1.0   \n",
       "14                0.0                1.0  ...             0.0       1.0   \n",
       "15                0.0                1.0  ...             0.0       NaN   \n",
       "16                0.0                1.0  ...             0.0       1.0   \n",
       "17                0.0                1.0  ...             0.0       NaN   \n",
       "18                0.0                1.0  ...             0.0       1.0   \n",
       "19                0.0                1.0  ...             0.0       1.0   \n",
       "20                0.0                1.0  ...             0.0       NaN   \n",
       "21                0.0                1.0  ...             0.0       1.0   \n",
       "22                0.0                1.0  ...             0.0       1.0   \n",
       "23                0.0                1.0  ...             0.0       1.0   \n",
       "24                0.0                1.0  ...             0.0       1.0   \n",
       "25                0.0                1.0  ...             0.0       1.0   \n",
       "26                0.0                1.0  ...             0.0       1.0   \n",
       "27                0.0                1.0  ...             0.0       1.0   \n",
       "28                0.0                1.0  ...             0.0       1.0   \n",
       "29                0.0                1.0  ...             0.0       1.0   \n",
       "\n",
       "    isNssmin  isNsscur  mainSystem1419max  mainSystem1419min  \\\n",
       "0        NaN       NaN                1.0                1.0   \n",
       "1        1.0       0.0                1.0                1.0   \n",
       "2        1.0       0.0                1.0                1.0   \n",
       "3        1.0       0.0                1.0                1.0   \n",
       "4        1.0       0.0                1.0                1.0   \n",
       "5        1.0       0.0                1.0                1.0   \n",
       "6        1.0       0.0                1.0                1.0   \n",
       "7        1.0       0.0                1.0                1.0   \n",
       "8        1.0       0.0                1.0                1.0   \n",
       "9        1.0       0.0                1.0                1.0   \n",
       "10       1.0       0.0                1.0                1.0   \n",
       "11       1.0       0.0                1.0                1.0   \n",
       "12       NaN       NaN                1.0                1.0   \n",
       "13       1.0       0.0                1.0                1.0   \n",
       "14       1.0       0.0                1.0                1.0   \n",
       "15       NaN       NaN                1.0                1.0   \n",
       "16       1.0       0.0                1.0                1.0   \n",
       "17       NaN       NaN                1.0                1.0   \n",
       "18       1.0       0.0                1.0                1.0   \n",
       "19       1.0       0.0                1.0                1.0   \n",
       "20       NaN       NaN                1.0                1.0   \n",
       "21       1.0       0.0                1.0                1.0   \n",
       "22       1.0       0.0                1.0                1.0   \n",
       "23       1.0       0.0                1.0                1.0   \n",
       "24       1.0       0.0                1.0                1.0   \n",
       "25       1.0       0.0                1.0                1.0   \n",
       "26       1.0       0.0                1.0                1.0   \n",
       "27       1.0       0.0                1.0                1.0   \n",
       "28       1.0       0.0                1.0                1.0   \n",
       "29       1.0       0.0                1.0                1.0   \n",
       "\n",
       "    mainSystem1419cur  monthServiceSummax  monthServiceSummin  \\\n",
       "0                 0.0                 NaN                 NaN   \n",
       "1                 0.0                 1.0            1.000000   \n",
       "2                 0.0                 1.0            1.017027   \n",
       "3                 0.0                 1.0            1.000000   \n",
       "4                 0.0                 NaN                 NaN   \n",
       "5                 0.0                 1.0            1.016086   \n",
       "6                 0.0                 1.0            1.016113   \n",
       "7                 0.0                 1.0            1.000000   \n",
       "8                 0.0                 NaN                 NaN   \n",
       "9                 0.0                 1.0            1.387566   \n",
       "10                0.0                 1.0            1.000000   \n",
       "11                0.0                 NaN                 NaN   \n",
       "12                0.0                 NaN                 NaN   \n",
       "13                0.0                 1.0            1.032993   \n",
       "14                0.0                 1.0            1.039846   \n",
       "15                0.0                 NaN                 NaN   \n",
       "16                0.0                 1.0            1.000000   \n",
       "17                0.0                 NaN                 NaN   \n",
       "18                0.0                 1.0            1.000000   \n",
       "19                0.0                 1.0            1.000000   \n",
       "20                0.0                 NaN                 NaN   \n",
       "21                0.0                 1.0            1.000000   \n",
       "22                0.0                 1.0            1.000000   \n",
       "23                0.0                 1.0            1.038161   \n",
       "24                0.0                 1.0            1.000000   \n",
       "25                0.0                 1.0            1.000000   \n",
       "26                0.0                 NaN                 NaN   \n",
       "27                0.0                 NaN                 NaN   \n",
       "28                0.0                 NaN                 NaN   \n",
       "29                0.0                 1.0            1.000000   \n",
       "\n",
       "    monthServiceSumcur  \n",
       "0                  NaN  \n",
       "1             32752.00  \n",
       "2             35063.03  \n",
       "3             24700.00  \n",
       "4                  NaN  \n",
       "5             12646.87  \n",
       "6              3983.62  \n",
       "7             18730.00  \n",
       "8                  NaN  \n",
       "9             10289.16  \n",
       "10            15437.00  \n",
       "11                 NaN  \n",
       "12                 NaN  \n",
       "13             7076.00  \n",
       "14             6209.96  \n",
       "15                 NaN  \n",
       "16             3000.00  \n",
       "17                 NaN  \n",
       "18             7186.00  \n",
       "19            13406.51  \n",
       "20                 NaN  \n",
       "21             8310.00  \n",
       "22            16033.00  \n",
       "23            61566.99  \n",
       "24            22695.80  \n",
       "25            40773.70  \n",
       "26                 NaN  \n",
       "27                 NaN  \n",
       "28                 NaN  \n",
       "29            14406.00  \n",
       "\n",
       "[30 rows x 267 columns]"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "excepted_columns=['paidDate','startdate','enddate','last_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sixMonthDebt'"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 29 42 63 65 102 108 123 128 132 137 185 211 246 251 319 338 342 361 447 535 538 555 557 589 612 640 710 711 712 722 836 851 877 894 909 914 930 962 968 969 1064 1103 1150 1211 1276 1325 1337 1345 1353 1355 1423 1458 1568 1602 1643 1776 1820 1835 1890 1907 1935 2024 2032 2055 2064 2065 2067 2071 2073 2074 2075 2076 2077 2078 2090 2129 2130 2132 2143 2145 2148 2152 2163 2244 2260 2302 2365 2368 2369 2391 2411 2416 2417 2455 2509 2532 2535 2547 2549 2596 2670 2742 2748 2787 2798 2805 2819 2820 2821 2840 2845 2871 2874 2884 2968 3012 3208 3210 3212 3227 3242 3250 3309 3342 3385 3503 3679 3815 3872 3915 4021 4026 4043 4121 4134 4149 4185 4191 4193 4194 4218 4303 4394 4412 4426 4458 4486 4488 4515 4518 4536 4541 4543 4553 4570 4614 4714 4715 4718 4725 4730 4741 4752 4766 4778 4781 4798 4800 4801 4804 4807 4825 4827 4828 4829 4842 4855 4861 4862 4872 4883 4886 4891 4950 4982 5003 5012 5016 5035 5042 5094 5111 5129 5134 5193 5222 5230 5285 5293 5297 5299 5314 5327 5331 5336 5342 5357 5395 5414 5418 5428 5446 5453 5479 5488 5538 5552 5561 5582 5589 5606 5610 5639 5646 5671 5675 5691 5693 5697 5703 5717 5776 5783 5784 5789 5792 5796 5841 5850 5854 5860 5866 5875 5889 5923 5934 5937 5944 5975 5998 6088 6143 6144 6157 6185 6205 6212 6223 6224 6230 6257 6302 6312 6326 6328 6333 6336 6339 6340 6353 6392 6411 6431 6467 6472 6536 6559 6562 6566 6567 6574 6580 6582 6595 6604 6608 6609 6623 6624 6644 6648 6657 6667 6674 6676 6701 6704 6707 6726 6728 6748 6772 6778 6799 6813 6815 6823 6849 6859 6862 6877 6886 6890 6891 6895 6901 6906 6907 6911 6927 6939 6940 6941 6946 6948 6992 7012 7024 7027 7030 7039 7042 7044 7051 7053 7055 7060 7062 7067 7072 7073 7076 7077 7080 7111 7117 7118 7127 7129 7142 7148 7153 7154 7164 7171 7176 7181 7182 7188 7189 7190 7198 7200 7207 7210 7214 7216 7218 7219 7220 7223 7225 7227 7228 7229 7230 7231 7232 7233 7234 7235 7236 7238 7246 7282 7292 7309 7312 7314 7315 7317 7318 7320 7321 7331 7332 7335 7339 7344 7347 7350 7366 7379 7395 7400 7405 7412 7413 7421 7423 7424 7429 7430 7431 7436 7443 7445 7448 7461 7464 7482 7484 7492 7495 7504 7514 7516 7517 7525 7526 7562 7577 7579 7589 7596 7598 7627 7632 7634 7638 7641 7648 7660 7683 7687 7688 7708 7710 7712 7722 7723 7724 7729 7748 7764 7776 7797 7798 7854 7862 7866 7868 7870 7872 7874 7881 7885 7888 7896 7904 7912 7916 7918 7920 7922 7927 7942 7959 7964 7982 7988 8003 8004 8008 8012 8018 8022 8027 8039 8040 8092 8093 8098 8110 8112 8121 8123 8137 8145 8149 8159 8165 8177 8189 8193 8197 8210 8213 8231 8241 8259 8263 8265 8268 8280 8281 8285 8288 8297 8302 8305 8306 8314 8338 8359 8362 8369 8377 8379 8407 8418 8444 8448 8451 8453 8457 8460 8472 8473 8475 8491 8494 8496 8507 8512 8516 8530 8538 8545 8552 8554 8561 8563 8592 8599 8620 8624 8629 8634 8636 8649 8656 8657 8659 8688 8693 8708 8712 8734 8751 8760 8761 8771 8792 8794 8807 8811 8814 8822 8829 8839 8840 8845 8847 8867 8869 8870 8871 8891 8908 8910 8913 8914 8919 8935 8941 8943 8952 8953 8983 8998 9000 9003 9005 9006 9025 9029 9033 9062 9064 9076 9077 9078 9103 9118 9121 9122 9126 9134 9137 9143 9145 9153 9183 9185 9186 9191 9218 9232 9234 9235 9252 9284 9285 9286 9287 9293 9323 9330 9335 9341 9343 9344 9348 9351 9365 9369 9381 9396 9408 9432 9439 9443 9446 9449 9451 9453 9456 9463 9465 9466 9469 9472 9473 9478 9483 9491 9512 9517 9521 9524 9538 9540 9546 9577 9586 9587 9588 9589 9590 9591 9592 9593 9598 9599 9607 9608 9609 9618 9619 9620 9621 9622 9623 9624 9625 9626 9627 9629 9630 9631 9634 9635 9640 9644 9645 9646 9653 9654 9655 9656 9657 9660 9661 9662 9663 9664 9665 9666 9673 9674 9675 9676 9677 9686 9708 9711 9715 9718 9722 9724 9730 9754 9781 9796 9798 9803 9831 9834 9849 9858 9880 9909 9910 9976 10005 10010 10039 10044 10058 10070 10112 10114 10122 10140 10167 10180 10198 10262 10276 10289 10297 10331 10333 10339 10341 10343 10372 10374 10378 10394 10402 10404 10408 10416 10423 10425 10429 10460 10464 10473 10481 10491 10509 10512 10517 10520 10529 10540 10560 10610 10612 10638 10650 10664 10683 10707 10717 10725 10774 10775 10780 10783 10840 10841 10842 10846 10900 10911 10922 10927 10929 10940 10941 10950 10966 11022 11073 11127 11132 11137 11167 11237 11244 11246 11250 11286 11288 11295 11298 11334 11337 11347 11350 11383 11410 11423 11473 11475 11480 11486 11489 11496 11498 11502 11503 11508 11512 11513 11539 11571 11583 11650 11658 11668 11680 11687 11706 11729 11742 11775 11787 11789 11817 11825 11833 11865 11895 11907 11913 11914 11918 11925 11947 11948 11949 11950 11951 11953 11954 11955 11956 11957 11958 11959 11960 11962 11963 11964 11965 11966 11967 11968 11969 11970 11971 11972 11973 11974 11975 11976 11977 11978 11979 11980 11981 11983 11984 11985 11986 11987 11988 11989 11990 11991 11992 11993 11994 11995 11996 11997 12047 12048 12075 12129 12160 12187 12189 12235 12245 12260 12264 12292 12313 12324 12327 12373 12408 12410 12432 12482 12507 12537 12567 12588 12626 12654 12684 12722 12727 12731 12743 12897 12908 12909 12910 12939 12954 12995 13001 13046 13058 13087 13142 13143 13686 13691 13723 13763 13770 13785 13794 13796 13798 13804 13824 13840 13850 13851 13860 13872 13880 13905 13923 13927 13937 13938 13939 13941 13942 13943 13946 13968 13972 13980 14005 14015 14033 14051 14055 14059 14067 14085 14120 14126 14129 14137 14138 14140 14160 14195 14204 14214 14215 14216 14225 14231 14233 14237 14238 14255 14274 14276 14327 14337 14350 14357 14367 14387 14392 14411 14438 14456 14500 14517 14519 14540 14575 14576 14619 14636 14649 14675 14706 14769 14801 14875 14904 14940 14968 15002 15034 15079 15243 15287 15344 15380 15425 15454 15459 15470 15477 15496 15552 15605 15631 15643 15665 15666 15713 15784 15847 15879 15906 15913 15918 15922 15925 15972 16016 16049 16051 16067 16072 16126 16127 16144 16164 16182 16219 16228 16235 16238 16239 16240 16241 16242 16243 16244 16256 16272 16311 16312 16347 16384 16387 16394 16395 16434 16442 16461 16512 16607 16610 16611 16627 16644 16653 16655 16669 16670 16671 16672 16673 16674 16675 16676 16677 16678 16679 16680 16681 16682 16683 16684 16685 16686 16687 16688 16689 16690 16691 16692 16693 16694 16695 16696 16697 16698 16699 16700 16701 16702 16704 16705 16706 16709 16710 16713 16715 16727 16732 16733 16735 16737 16750 16762 16780 16795 16807 16808 16811 16816 16819 16821 16825 16830 16834 16900 16950 16951 16974 16988 16997 17008 17009 17010 17012 17013 17016 17018 17048 17066 17068 17069 17076 17087 17099 17140 17148 17151 17153 17173 17192 17203 17214 17219 17238 17239 17243 17244 17248 17264 17269 17305 17313 17315 17318 17319 17321 17322 17370 17371 17374 17397 17398 17405 17412 17416 17421 17427 17437 17443 17449 17450 17455 17459 17468 17470 17474 17475 17476 17477 17478 17479 17482 17490 17491 17492 17494 17497 17499 17501 17504 17508 17529 17530 17531 17542 17552 17569 17576 17606 17643 17650 17668 17687 17690 17706 17740 17788 17794 17805 17814 17823 17824 17855 17867 17871 17879 17883 17915 17927 17929 17958 17966 17985 18012 18067 18068 18071 18108 18155 18159 18167 18176 18180 18181 18182 18189 18197 18247 18252 18253 18254 18255 18257 18258 18259 18260 18261 18262 18263 18264 18265 18266 18267 18268 18284 18292 18293 18294 18295 18296 18297 18298 18299 18301 18302 18303 18304 18311 18398 18400 18401 18404 18416 18423 18462 18476 18477 18552 18554 18560 18577 18602 18621 18641 18642 18679 18696 18704 18771 18772 18784 18785 18891 18897 18966 18972 19032 19068 19073 19148 19174 19208 19212 19244 19281 19291 19295 19299 19302 19311 19319 19320 19331 19354 19369 19396 19461 19485 19519 19547 19601 19630 19735 19742 19788 19802 19823 19841 19947 19993 20000 20001 20003 20004 20007 20024 20034 20038 20049 20050 20062 20116 20234 20251 20253 20267 20302 20303 20322 20330 20345 20347 20349 20354 20374 20415 20421 20458 20473 20522 20583 20602 20637 20667 20703 20724 20739 20740 20741 20747 20800 20802 20811 20823 20832 20848 20872 20880 20882 20886 20888 20902 20908 20916 20940 20944 20947 20990 20993 20996 20999 21000 21001 21002 21003 21004 21005 21009 21018 21030 21032 21035 21036 21037 21038 21045 21070 21097 21099 21107 21146 21221 21228 21231 21275 21284 21286 21289 21292 21296 21297 21298 21300 21305 21306 21333 21341 21361 21364 21370 21393 21396 21402 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21409 21414 21418 21459 21464 21465 21484 21496 21497 21498 21499 21511 21514 21580 21596 21597 21600 21601 21607 21611 21626 21627 21637 21638 21651 21660 21661 21681 21686 21706 21722 21750 21751 21763 21766 21780 21783 21809 21812 21813 21816 21821 21867 21900 21902 21936 21947 21948 21994 22035 22039 22069 22071 22126 22129 22132 22133 22134 22135 22142 22146 22149 22152 22172 22179 22201 22222 22228 22236 22238 22250 22255 22294 22315 22334 22366 22388 22397 22454 22469 22480 22481 22482 22483 22493 22517 22544 22551 22565 22591 22601 22647 22654 22745 22778 22783 22822 22836 22871 22919 22925 22992 23105 23129 23130 23131 23174 23265 23288 23329 23358 23363 23364 23369 23390 23445 23466 23505 23544 23599 23632 23633 23634 23637 23659 23718 23720 23758 23762 23766 23767 23772 23775 23778 23815 23817 23825 23864 23877 23888 23889 23897 23898 23911 23916 23923 23927 23937 23938 23945 23952 23962 23995 24093 24124 24136 24185 24186 24207 24228 24252 24284 24311 24327 24353 24391 24410 24411 24515 24553 24560 24600 24632 24658 24685 24694 24716 24720 24725 24727 24733 24734 24736 24765 24783 24784 24790 24796 24807 24823 24825 24826 24852 24853 24854 24855 24856 24876 24905 24925 24926 24935 24945 24955 24985 25002 25007 25015 25053 25099 25104 25106 25121 25127 25131 25164 25201 25231 25232 25240 25241 25242 25243 25244 25245 25259 25292 25311 25323 25335 25365 25376 25384 25386 25454 25481 25492 25493 25494 25513 25527 25531 25562 25588 25590 25591 25594 25600 25601 25634 25644 25651 25662 25731 25732 25733 25734 25735 25749 25750 25760 25782 25799 25800 25801 25803 25806 25847 25862 25899 25904 25905 25930 25962 25969 26009 26026 26032 26033 26034 26035 26036 26038 26039 26052 26058 26074 26095 26104 26134 26145 26190 26191 26200 26222 26230 26263 26264 26283 26284 26285 26286 26287 26288 26289 26290 26291 26294 26295 26296 26297 26298 26299 26300 26346 26350 26387 26389 26404 26409 26413 26425 26452 26453 26462 26463 26498 26544 26573 26604 26629 26664 26670 26697 26722 26747 26753 26755 26756 26757 26758 26759 26760 26761 26769 26779 26788 26922 26925 26968 26975 26997 27019 27056 27058 27059 27060 27093 27124 27131 27132 27137 27165 27187 27200 27222 27263 27286 27288 27290 27427 27436 27445 27546 27547 27555 27579 27587 27593 27608 27621 27640 27718 27880 27884 27908 27914 27935 27942 27957 27966 28007 28019 28046 28294 28302 28338 28360 28369 28384 28424 28437 28511 28533 28602 28651 28671 28681 28707 28722 28747 28799 28809 28884 28899 28901 28919 28972 28973 28981 28996 28997 29005 29058 29076 29094 29101 29185 29189 29203 29227 29249 29274 29296 29307 29412 29421 29464 29480 29484 29498 29510 29516 29532 29540 29544 29580 29584 29590 29622 29646 29665 29680 29758 29792 29815 29828 29836 29841 29859 29877 29881 29899 29979 29996 30018 30020 30022 30060 30061 30069 30073 30102 30103 30112 30164 30205 30251 30281 30316 30367 30405 30433 30448 30454 30461 30548 30552 30600 30604 30660 30663 30668 30669 30693 30793 30801 30802 30837 30839 30840 30841 30842 30843 30844 30845 30846 30865 30882 30883 30884 30904 30909 30943 31023 31038 31073 31099 31109 31145 31182 31192 31198 31209 31245 31261 31264 31288 31292 31325 31375 31392 31396 31398 31403 31419 31497 31514 31537 31606 31607 31615 31715 31734 31804 31808 31831 31874 32041 32109 32199 32215 32220 32227 32261 32278 32304 32309 32317 32328 32352 32360 32387 32392 32415 32444 32450 32493 32494 32495 32497 32500 32531 32534 32553 32562 32575 32623 32644 32651 32656 32660 32672 32718 32739 32746 32747 32762 32763 32818 32843 32846 32849 32905 32906 32915 32921 32944 32993 33086 33098 33152 33163 33233 33257 33290 33293 33298 33342 33359 33465 33485 33520 33539 33595 33599 33605 33695 33729 33751 33774 33787 33794 33799 33826 33923 34001 34035 34119 34122 34129 34220 34221 34222 34226 34259 34288 34354 34362 34364 34400 34420 34435 34439 34467 34468 34469 34478 34506 34516 34555 34564 34599 34601 34610 34628 34647 34667 34668 34669 34674 34706 34748 34864 34887 34908 34997 34998 35000 35003 35009 35016 35157 35276 35306 35309 35317 35319 35349 35358 35436 35462 35468 35502 35519 35521 35549 35573 35629 35632 35737 35752 35891 35961 36056 36058 36170 36200 36203 36263 36272 36288 36314 36344 36360 36383 36391 36402 36409 36425 36431 36438 36458 36466 36650 36651 36654 36655 36657 36694 36699 36701 36731 36862 36899 36912 36919 36922 36928 36929 36930 36931 36938 36947 36952 36962 36973 36974 37049 37077 37084 37091 37104 37137 37207 37216 37234 37257 37258 37284 37291 37292 37294 37296 37302 37305 37307 37330 37336 37338 37339 37341 37405 37557 37647 37661 37740 37742 37763 37769 37787 37815 37862 37874 37896 37898 37909 37910 37915 37923 37935 37965 37994 38020 38093 38165 38218 38236 38249 38309 38375 38390 38461 38484 38546 38604 38607 38618 38621 38671 38689 38744 38762 38789 38906 38921 38984 39020 39040 39071 39072 39095 39108 39138 39209 39220 39262 39350 39390 39400 39404 39469 39489 39490 39563 39616 39622 39623 39658 39659 39663 39665 39713 39721 39769 39786 39787 39947 39962 39964 39981 39982 40006 40027 40056 40067 40075 40081 40148 40152 40198 40255 40363 40383 40467 40497 40510 40512 40517 40526 40571 40618 40635 40651 40683 40686 40732 40771 40825 40931 40939 41081 41120 41183 41204 41208 41212 41514 41552 41557 41588 41594 41598 41658 41664 41675 41676 41725 41858 41924 41981 42003 42024 42030 42097 42101 42129 42132 42139 42148 42149 42184 42253 42294 42301 42309 42325 42333 42345 42355 42356 42359 42377 42384 42388 42413 42416 42551 42663 42793 42822 42856 42872 42881 42902 42906 42915 42944 43144 43158 43194 43201 43234 43237 43256 43287 43314 43353 43354 43479 43485 43534 43548 43571 43582 43637 43658 43726 43727 43742 43814 43836 43900 43912 43982 43996 44007 44013 44025 44029 44116 44210 44212 44295 44297 44310 44351 44388 44391 44411 44430 44434 44478 44526 44575 44624 44625 44626 44627 44628 44630 44631 44633 44634 44691 44764 44788 44865 44923 44938 45008 45009 45032 45075 45138 45195 45252 45305 45357 45424 45433 45501 45512 45531 45623 45631 45753 45790 45879 45900 46002 46038 46049 46188 46200 46324 46393 46406 46491 46572 46631 46688 46742 46755 46759 46778 46782 46883 46952 46956 46959 46966 46974 47017 47021 47076 47080 47093 47161 47164 47202 47233 47311 47355 47406 47461 47473 47493 47552 47583 47709 47777 47784 47833 47881 47882 47906 47983 47986 48294 48315 48347 48368 48369 48371 48373 48375 48376 48377 48379 48381 48421 48479 48481 48491 48501 48535 48538 48549 48613 48699 48713 48734 48786 48813 48832 48941 49018 49028 49033 49047 49062 49084 49185 49201 49231 49233 49284 49287 49357 49503 49524 49535 49542 49639 49682 49693 49728 49810 49864 49917 49932 49948 49949 49950 49958 49961 49969 49972 49987 50000 50004 50005 50007 50009 50012 50013 50014 50016 50017 50018 50019 50020 50021 50022 50023 50024 50025 50026 50027 50030 50031 50032 50033 50034 50035 50038 50039 50044 50058 50059 50062 50063 50064 50065 50066 50069 50070 50071 51157 51806 51810 51831 51839 53447 53496 53497 53647 56411 56686 56718 56719 61280 68299 71806 73713 81512 85896 88812 88813 91652 91654 95350 100350 102072 106900 106902 125972 130421 131676 132223 132275 132279 132282 132385 132386 132392 134523 134534 137479 138842 141680 154427 154440 158417 158422 158450 158545 158567 158602 158606 159158 164978 165026 165028 165677 165683 165936 165937 165947 165948 166659 166660 166664 175941 177958 177965 178581 178637 179166 179414 179416 179422 179423 179425 179429 179432 189026 190385 190594 190606 190610 190613 190702 190816 191120 191370 191383 191403 191479 191517 191523 191528 191658 191666 192493 192515 193850 194496 213962 216716 216905 217920 218058 218061 218065 218347 218421 220437 220592 220598 220599 220605 232343 232988 233235 233252 233282 233378 233748 233766 233892 233924 233927 233949 234020 234194 234195 234651 234652 234653 234654 234655 234656 234657 234658 234659 234661 234662 234663 234664 234665 234666 234667 234668 234669 234670 234671 234755 235127 235128 235129 235130 235131 235132 235133 235134 235137 235138 235139 235140 235141 235142 235144 254813 254815 267111 279399 279408 279411 279415 279947 280172 280178 298813 299713 310920 310949 311046 311225 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311231 311234 311237 313109 313160 313163 313742 321236 321239 322850 328870 331652 331656 331658 331662 331665 347104 347105 347111 347112 347113 352718 352720 353651 354592 355333 360803 360804 360810 362486 366876 366880 366964 366967 366969 366990 367028 367029 367169 367607 367686 367703 374004 374005 374099 374280 374286 374292 374295 374296 374324 374354 374409 374589 374623 374625 374626 374627 374628 382004 392255 392261 392262 392268 392271 392275 392279 392283 392293 392304 392316 392322 392492 392567 392569 392571 392573 392574 392803 401496 414053 417401 417404 417428 417595 417605 469962 470668 472106 484902 484909 495236 495254 495262 495443 495444 495457 495463 495469 495486 495489 525119 525133 553354 553363 553561 553565 553593 553798 553868 553869 553881 553884 554329 554508 614841 637904 637923 637935 637941 637944 637945 637948 637949 637954 637956 637957 637958 638161 640478 642712 642842 642947 642983 662307 662334 662431 662591 662600 662602 662712 662909 663093 680987 680996 715684 715685 742099 745368 746355 749418 750272 750363 750378 750387 750389 750559 750606 750617 750635 750878 750900 750912 750920 750933 816452 816461 816607 816655 816656 816661 816725 816764 816775 816778 816916 820930 821042 821140 821292 842148 842153 842192 858561 858566 858618 858906 858947 859097 866771 868464 880206 880211 880213 880349 880468 880487 880495 880502 880621 880624 880656 880700 880705 880706 880709 903002 924179 924229 924231 924765 924951 925010 925011 925014 925015 925016 925018 925170 925171 925179 925296 925298 925301 925333 925846 925848 925955 926363 926604 926606 926881 926903 927289 927311 927387 927434 927448 927531 927603 927633 927800 927803 927810 928284 928292 928297 930124 932926 934802 937772 939358 939635 941327 941330 941332 941333 941334 941335 941336 941337 941340 941346 949945 949949 950169 970297 970415 970419 970510 970514 970534 970535 970536 970537 970538 970539 970540 970541 970628 970638 970649 985281 985302 985310 985461 985462 985468 985470 985539 985589 985723 985789 985810 986288 986312 986446 986451 986462 986464 986596 987346 987369 987578 987581 995739 996051 996140 996165 996258 996261 996262 996268 996270 996277 996426 996431 996932 996938 1000662 1000667 1000668 1000690 1039183 1039511 1039913 1040048 1040064 1040068 1040369 1040745 1056126 1085951 1086366 1086431 1086486 1086500 1086532 1086540 1086541 1086547 1086596 1086705 1087106 1087363 1087471 1088087 1088208 1088264 1089159 1089350 1089352 1089353 1089461 1089723 1089724 1089760 1089761 1089773 1090316 1090322 1090326 1090627 1090877 1090891 1090892 1090895 1090897 1090901 1090902 1090942 1091017 1091053 1091112 1091139 1091178 1096069 1096278 1096550 1096683 1096780 1096782 1097727 1097729 1097879 1098258 1098648 1098651 1098657 1098658 1098668 1098831 1098947 1099907 1099930 1099931 1099934 1099938 1099944 1099950 1099959 1099986 1099995 1100005 1100029 1100083 1100842 1100845 1101606 1101760 1101848 1166145 1166146 1166151 1166226 1166849 1166861 1166947 1166975 1166976 1166988 1167025 1224841 1282813 1323099 1323105 1323655 1323660 1323675 1323684 1323802 1323879 1332954 1334169 1334705 1338413 1366804 1366995 1367016 1367065 1367591 1367632 1367638 1367662 1367869 1367899 1373141 1373168 1373229 1373231 1373238 1373521 1373700 1375814 1376043 1377040 1377143 1377145 1377172 1377175 1377198 1377199 1377200 1377308 1377337 1377768 1378094 1378210 1378452 1378766 1378767 1378784 1378789 1385648 1386036 1386046 1386052 1386053 1389319 1389336 1389376 1389385 1390273 1390847 1391340 1392129 1392572 1392574 1392636 1392638 1392655 1392681 1392805 1393328 1400189 1423545 1431661 1439132 1439752 1439792 1439820 1439824 1439829 1439896 1440646 1440708 1441030 1441110 1441765 1441792 1442578 1442676 1442861 1442974 1442983 1443053 1443056 1443099 1443120 1443194 1443218 1443339 1443410 1444247 1446196 1446270 1446291 1446305 1446306 1446369 1446370 1446371 1446372 1446375 1446376 1446380 1446386 1447867 1450156 1450165 1450635 1450706 1450708 1450720 1450742 1450855 1451431 1452061 1452216 1452220 1452299 1452317 1452346 1452801 1454681 1455012 1455610 1467829 1468193 1469906 1469925 1470646 1470677 1470697 1471027 1471714 1471804 1471808 1471898 1471905 1471981 1472462 1485567 1485709 1485802 1485889 1486006 1486330 1486435 1486569 1486571 1486573 1486675 1486876 1486975 1487814 1489008 1489009 1489012 1489111 1489115 1489117 1489135 1489250 1489263 1489265 1489423 1489425 1489962 1490530 1490659 1491391 1491487 1491871 1492700 1493823 1494209 1494279 1497717 1498103 1498988 1501653 1501799 1501858 1503107 1505990 1506637 1506638 1506640 1506641 1506642 1526109 1526110 1526135 1531180 1531780 1531888 1532302 1532305 1532306 1532346 1532347 1535226 1535334 1535354 1535367 1535408 1540533 1540660 1540877 1546744 1546745 1546746 1546877 1546934 1546935 1546937 1546938 1547086 1547600 1547663 1547693 1547770 1547854 1548521 1550545 1550600 1550830 1550849 1551294 1552090 1552300 1553069 1553161 1553694 1554064 1554065 1554326 1554336 1554345 1554486 1554512 1554727 1554731 1554732 1554755 1554760 1554762 1554911 1555199 1555200 1555202 1555213 1555486 1555604 1555621 1555629 1555630 1556543 1556544 1556562 1556563 1556635 1556783 1556917 1556942 1557701 1557702 1557730 1557731 1557732 1557868 1557869 1558003 1559235 1559291 1559303 1559326 1559927 1559930 1559931 1559938 1559939 1559942 1559943 1560243 1560245 1560246 1560248 1560250 1560251 1560377 1560552 1560553 1560554 1560560 1560572 1560799 1560800 1560801 1560806 1560807 1562975 1565764 1565765 1565768 1565774 1565787 1565788 1565789 1565790 1566222 1566992 1567410 1567413 1567518 1568459 1568501 1568503 1568507 1568522 1568523 1568610 1569053 1569276 1569281 1570141 1570155 1570157 1570160 1570161 1570169 1570823 1570826 1570829 1570830 1570885 1572190 1572207 1572247 1572254 1572277 1572312 1572350 1572353 1572371 1572402 1572711 1576076 1576079 1576098 1576972 1577028 1577977 1578390 1578392 1578395 1578405 1578406 1579713 1579768 1579851 1580131 1580241 1581913 1582251 1582264 1582493 1582572 1582595 1582615 1582632 1582656 1582666 1582825 1582833 1583540 1583546 1583875 1584025 1584027 1584037 1584730 1584974 1584978 1585090 1585354 1585989 1586340 1586381 1586934 1586938 1586940 1586946 1587464 1587466 1587710 1588626 1588664 1588689 1588749 1588944 1588975 1589448 1589450 1590390 1590549 1590606 1590613 1590615 1590636 1590644 1590656 1590664 1590675 1590684 1590687 1590688 1590694 1590698 1590708 1590709 1590723 1591408 1591624 1591626 1591627 1591630 1591639 1591650 1591651 1591657 1591665 1591666 1591671 1591700 1591714 1591715 1591717 1591746 1591753 1591754 1592899 1592905 1592906 1597142 1597143 1597151 1597152 1597156 1597158 1597333 1598052 1598084 1598088 1598875 1598881 1598902 1598912 1600016 1600017 1600258 1600385 1600652 1600657 1600662 1600667 1600671 1600708 1600714 1600724 1600744 1601099 1601304 1601379 1601382 1601385 1601395 1601806 1602168 1602197 1603067 1603408 1603519 1603544 1603546 1603554 1603557 1603564 1603570 1603572 1603924 1603928 1604034 1604036 1604038 1604048 1604050 1604057 1604058 1604436 1604570 1606505 1606539 1606847 1606866 1606880 1606889 1606890 1606894 1606895 1607128 1607137 1607144 1607145 1607146 1607187 1607189 1607222 1607232 1607705 1607706 1607710 1607996 1608957 1609164 1609233 1609246 1609753 1609781 1610125 1610271 1610273 1610812 1611276 1611277 1611280 1611287 1611289 1611751 1611756 1611757 1611763 1611764 1611765 1611767 1611769 1611771 1611774 1611790 1611794 1611803 1611808 1611816 1611825 1611879 1611880 1613038 1613900 1613902 1613954 1614017 1614028 1614055 1614067 1614078 1614088 1614112 1614117 1614124 1614131 1614141 1614142 1614145 1614146 1614149 1614154 1614156 1614170 1614171 1614176 1614183 1614184 1614195 1614198 1614199 1614206 1614207 1614208 1614216 1614219 1614222 1614225 1614229 1614230 1614595 1614991 1614996 1614999 1615001 1615002 1615006 1615015 1615016 1615024 1615028 1615029 1617346 1617347 1618361 1618362 1618363 1618368 1618369 1618379 1618385 1618387 1618391 1618392 1618395 1618774 1618777 1618779 1618781 1618786 1618790 1618791 1618792 1618794 1619122 1619123 1619125 1619129 1619133 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1619138 1619139 1619142 1619143 1619148 1619150 1619151 1619153 1619156 1619158 1619161 1619162 1619163 1620720 1622477 1622481 1622484 1622485 1622487 1622498 1622503 1622520 1622527 1626377 1627468 1627502 1628924 1628926 1629624 1629627 1629629 1629636 1629638 1629644 1629650 1629660 1629667 1629669 1629671 1630843 1630866 1630867 1631845 1631847 1631850 1631851 1631859 1632872 1632875 1632881 1632882 1632884 1632885 1633412 1633420 1633430 1633435 1633800 1633807 1633808 1633809 1633813 1633814 1633957 1633961 1633964 1633970 1633976 1633977 1633980 1633981 1633996 1634006 1634008 1634009 1634011 1634014 1634016 1634017 1634020 1634536 1634537 1634540 1634552 1634553 1634557 1634559 1634565 1634566 1634573 1634576 1634580 1634586 1634591 1634592 1634593 1634594 1634967 1635288 1636503 1637118 1637121 1637124 1637126 1637127 1637129 1637137 1637415 1637630 1637631 1637632 1637636 1637641 1637647 1637649 1637650 1637660 1637669 1637670 1638576 1638580 1639132 1639140 1639143 1639146 1639149 1639150 1639151 1639152 1639159 1639160 1640087 1640101 1640609 1641343 1641345 1641346 1641356 1641360 1641373 1641374 1641379 1641380 1642225 1642228 1642231 1642293 1642305 1642819 1642824 1642830 1643631 1643784 1643786 1643788 1643789 1643795 1644716 1644721 1650324 1653361 1653363 1654370 1654838 1654839 1654846 1654852 1654853 1655120 1655122 1655131 1656134 1656136 1656143 1656148 1656678 1656679 1656684 1656758 1656759 1658035 1658764 1659072 1659077 1659094 1659096 1659102 1660255 1660689 1661196 1661607 1661620 1662139 1662140 1662153 1662169 1662176 1662669 1662673 1662692 1662697 1663689 1663691 1663710 1663713 1663720 1664387 1664392 1664399 1664850 1664854 1664856 1664862 1664984 1664987 1665258 1665589 1665592 1665593 1665596 1665597 1665601 1665602 1665630 1666037 1666038 1666580 1666581 1666589 1666590 1666597 1666607 1666609 1666620 1667893 1667903 1667924 1667926 1667933 1667934 1668807 1668828 1668832 1668836 1668841 1670156 1670170 1670174 1670645 1670649 1670653 1670655 1670664 1670667 1670669 1670676 1670684 1670685 1670688 1670689 1670690 1670698 1670738 1670741 1671316 1671320 1671326 1671345 1671346 1671347 1671357 1671366 1671771 1671828 1671848 1672162 1673264 1673278 1673304 1673317 1673322 1673330 1673339 1673349 1673395 1673440 1673448 1673550 1673552 1673553 1673572 1673588 1673621 1674090 1674092 1674099 1674102 1674114 1674699 1674931 1675214 1675220 1675223 1675231 1675234 1675246 1675247 1675253 1675280 1675282 1675283 1675293 1675594 1675635 1675636 1675638 1675958 1676180 1676181 1676182 1676184 1676693 1677041 1677668 1677676 1681724 1681736 1681740 1681749 1683259 1683572 1683579 1684113 1684272 1684274 1684651 1684656 1689503 1689511 1689521 1689528 1689959 1689984 1690027 1691304 1692840 1692841 1692845 1692846 1694902 1694910 1694917 1694948 1696287 1696317 1696323 1696385 1696463 "
     ]
    }
   ],
   "source": [
    "eps=1e-9\n",
    "columns=list(set(list(df))-set('id'))\n",
    "for id in unique_id:\n",
    "    print(id,end=' ')\n",
    "    for col in columns:\n",
    "        if col in excepted_columns:\n",
    "            continue\n",
    "        max_value=df.loc[(df.id==id)&(df.startdate>df.last_month-pd.Timedelta(days=182))][col].astype(float).max()\n",
    "        min_value=df.loc[(df.id==id)&(df.startdate>df.last_month-pd.Timedelta(days=182))][col].astype(float).min()\n",
    "        cur_value=df.loc[(df.id==id)&(df.last_month==df.startdate)][col].astype(float).max()\n",
    "#         print(id,col,max_value)\n",
    "        client_data.loc[client_data.id==id,col+'max']=(cur_value+eps)/(max_value+eps)\n",
    "        client_data.loc[client_data.id==id,col+'min']=(cur_value+eps)/(min_value+eps)\n",
    "        client_data.loc[client_data.id==id,col+'cur']=cur_value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4260, 279)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2543"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_data['employeerQNewmax'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_data1=client_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=client_data1.drop(['is_gone','last_month','id'],axis=1)\n",
    "y=client_data1.is_gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4260, 264), (4260,))"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3408, 264])"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 1.0161e+00,\n",
       "         3.9836e+03],\n",
       "        ...,\n",
       "        [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 1.0000e+00,\n",
       "         4.8222e+03],\n",
       "        [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00]], dtype=torch.float64)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=torch.DoubleTensor(X_train.values)\n",
    "X_test=torch.DoubleTensor(X_test.values)\n",
    "y_train=torch.LongTensor(y_train.values)\n",
    "y_test=torch.LongTensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3408, 264])"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=3408\n",
    "lr=1e-4\n",
    "num_epoch=1000\n",
    "step_size=200\n",
    "gamma=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "class API_net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(API_net,self).__init__()\n",
    "        self.fc1=torch.nn.Linear(264,500)\n",
    "        self.act1=torch.nn.ReLU()\n",
    "        self.fc2=torch.nn.Linear(500,500)\n",
    "        self.act2=torch.nn.Tanh()\n",
    "        self.fc3=torch.nn.Linear(500,2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.fc1(x)\n",
    "        x=self.act1(x)\n",
    "        x=self.fc2(x)\n",
    "        x=self.act2(x)\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model=API_net().double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0/999:\n",
      "train loss  tensor(0.6687, dtype=torch.float64)\n",
      "train acc   tensor(0.5472)\n",
      "\n",
      "Epoch 1/999:\n",
      "train loss  tensor(0.6370, dtype=torch.float64)\n",
      "train acc   tensor(0.6312)\n",
      "\n",
      "Epoch 2/999:\n",
      "train loss  tensor(0.6376, dtype=torch.float64)\n",
      "train acc   tensor(0.6394)\n",
      "\n",
      "Epoch 3/999:\n",
      "train loss  tensor(0.6331, dtype=torch.float64)\n",
      "train acc   tensor(0.6479)\n",
      "\n",
      "Epoch 4/999:\n",
      "train loss  tensor(0.6286, dtype=torch.float64)\n",
      "train acc   tensor(0.6511)\n",
      "\n",
      "Epoch 5/999:\n",
      "train loss  tensor(0.6195, dtype=torch.float64)\n",
      "train acc   tensor(0.6535)\n",
      "\n",
      "Epoch 6/999:\n",
      "train loss  tensor(0.6152, dtype=torch.float64)\n",
      "train acc   tensor(0.6546)\n",
      "\n",
      "Epoch 7/999:\n",
      "train loss  tensor(0.6079, dtype=torch.float64)\n",
      "train acc   tensor(0.6552)\n",
      "\n",
      "Epoch 8/999:\n",
      "train loss  tensor(0.6155, dtype=torch.float64)\n",
      "train acc   tensor(0.6520)\n",
      "\n",
      "Epoch 9/999:\n",
      "train loss  tensor(0.6032, dtype=torch.float64)\n",
      "train acc   tensor(0.6540)\n",
      "\n",
      "Epoch 10/999:\n",
      "train loss  tensor(0.5918, dtype=torch.float64)\n",
      "train acc   tensor(0.6491)\n",
      "\n",
      "Epoch 11/999:\n",
      "train loss  tensor(0.5860, dtype=torch.float64)\n",
      "train acc   tensor(0.6520)\n",
      "\n",
      "Epoch 12/999:\n",
      "train loss  tensor(0.5777, dtype=torch.float64)\n",
      "train acc   tensor(0.6505)\n",
      "\n",
      "Epoch 13/999:\n",
      "train loss  tensor(0.5682, dtype=torch.float64)\n",
      "train acc   tensor(0.6546)\n",
      "\n",
      "Epoch 14/999:\n",
      "train loss  tensor(0.5629, dtype=torch.float64)\n",
      "train acc   tensor(0.6585)\n",
      "\n",
      "Epoch 15/999:\n",
      "train loss  tensor(0.5632, dtype=torch.float64)\n",
      "train acc   tensor(0.6579)\n",
      "\n",
      "Epoch 16/999:\n",
      "train loss  tensor(0.5620, dtype=torch.float64)\n",
      "train acc   tensor(0.6570)\n",
      "\n",
      "Epoch 17/999:\n",
      "train loss  tensor(0.5522, dtype=torch.float64)\n",
      "train acc   tensor(0.6570)\n",
      "\n",
      "Epoch 18/999:\n",
      "train loss  tensor(0.5470, dtype=torch.float64)\n",
      "train acc   tensor(0.6611)\n",
      "\n",
      "Epoch 19/999:\n",
      "train loss  tensor(0.5375, dtype=torch.float64)\n",
      "train acc   tensor(0.6602)\n",
      "\n",
      "Epoch 20/999:\n",
      "train loss  tensor(0.5321, dtype=torch.float64)\n",
      "train acc   tensor(0.6614)\n",
      "\n",
      "Epoch 21/999:\n",
      "train loss  tensor(0.5241, dtype=torch.float64)\n",
      "train acc   tensor(0.7344)\n",
      "\n",
      "Epoch 22/999:\n",
      "train loss  tensor(0.5189, dtype=torch.float64)\n",
      "train acc   tensor(0.7412)\n",
      "\n",
      "Epoch 23/999:\n",
      "train loss  tensor(0.5167, dtype=torch.float64)\n",
      "train acc   tensor(0.7450)\n",
      "\n",
      "Epoch 24/999:\n",
      "train loss  tensor(0.5111, dtype=torch.float64)\n",
      "train acc   tensor(0.7386)\n",
      "\n",
      "Epoch 25/999:\n",
      "train loss  tensor(0.5062, dtype=torch.float64)\n",
      "train acc   tensor(0.7418)\n",
      "\n",
      "Epoch 26/999:\n",
      "train loss  tensor(0.5011, dtype=torch.float64)\n",
      "train acc   tensor(0.7541)\n",
      "\n",
      "Epoch 27/999:\n",
      "train loss  tensor(0.4981, dtype=torch.float64)\n",
      "train acc   tensor(0.7661)\n",
      "\n",
      "Epoch 28/999:\n",
      "train loss  tensor(0.4898, dtype=torch.float64)\n",
      "train acc   tensor(0.7758)\n",
      "\n",
      "Epoch 29/999:\n",
      "train loss  tensor(0.4836, dtype=torch.float64)\n",
      "train acc   tensor(0.7785)\n",
      "\n",
      "Epoch 30/999:\n",
      "train loss  tensor(0.4794, dtype=torch.float64)\n",
      "train acc   tensor(0.7673)\n",
      "\n",
      "Epoch 31/999:\n",
      "train loss  tensor(0.4755, dtype=torch.float64)\n",
      "train acc   tensor(0.7705)\n",
      "\n",
      "Epoch 32/999:\n",
      "train loss  tensor(0.4749, dtype=torch.float64)\n",
      "train acc   tensor(0.7702)\n",
      "\n",
      "Epoch 33/999:\n",
      "train loss  tensor(0.4689, dtype=torch.float64)\n",
      "train acc   tensor(0.7685)\n",
      "\n",
      "Epoch 34/999:\n",
      "train loss  tensor(0.4649, dtype=torch.float64)\n",
      "train acc   tensor(0.7767)\n",
      "\n",
      "Epoch 35/999:\n",
      "train loss  tensor(0.4615, dtype=torch.float64)\n",
      "train acc   tensor(0.7785)\n",
      "\n",
      "Epoch 36/999:\n",
      "train loss  tensor(0.4595, dtype=torch.float64)\n",
      "train acc   tensor(0.7811)\n",
      "\n",
      "Epoch 37/999:\n",
      "train loss  tensor(0.4568, dtype=torch.float64)\n",
      "train acc   tensor(0.7799)\n",
      "\n",
      "Epoch 38/999:\n",
      "train loss  tensor(0.4532, dtype=torch.float64)\n",
      "train acc   tensor(0.7802)\n",
      "\n",
      "Epoch 39/999:\n",
      "train loss  tensor(0.4496, dtype=torch.float64)\n",
      "train acc   tensor(0.7702)\n",
      "\n",
      "Epoch 40/999:\n",
      "train loss  tensor(0.4474, dtype=torch.float64)\n",
      "train acc   tensor(0.7732)\n",
      "\n",
      "Epoch 41/999:\n",
      "train loss  tensor(0.4453, dtype=torch.float64)\n",
      "train acc   tensor(0.7732)\n",
      "\n",
      "Epoch 42/999:\n",
      "train loss  tensor(0.4431, dtype=torch.float64)\n",
      "train acc   tensor(0.8040)\n",
      "\n",
      "Epoch 43/999:\n",
      "train loss  tensor(0.4429, dtype=torch.float64)\n",
      "train acc   tensor(0.8055)\n",
      "\n",
      "Epoch 44/999:\n",
      "train loss  tensor(0.4361, dtype=torch.float64)\n",
      "train acc   tensor(0.8046)\n",
      "\n",
      "Epoch 45/999:\n",
      "train loss  tensor(0.4346, dtype=torch.float64)\n",
      "train acc   tensor(0.8046)\n",
      "\n",
      "Epoch 46/999:\n",
      "train loss  tensor(0.4302, dtype=torch.float64)\n",
      "train acc   tensor(0.8069)\n",
      "\n",
      "Epoch 47/999:\n",
      "train loss  tensor(0.4277, dtype=torch.float64)\n",
      "train acc   tensor(0.8081)\n",
      "\n",
      "Epoch 48/999:\n",
      "train loss  tensor(0.4284, dtype=torch.float64)\n",
      "train acc   tensor(0.8090)\n",
      "\n",
      "Epoch 49/999:\n",
      "train loss  tensor(0.4265, dtype=torch.float64)\n",
      "train acc   tensor(0.8069)\n",
      "\n",
      "Epoch 50/999:\n",
      "train loss  tensor(0.4240, dtype=torch.float64)\n",
      "train acc   tensor(0.8169)\n",
      "\n",
      "Epoch 51/999:\n",
      "train loss  tensor(0.4216, dtype=torch.float64)\n",
      "train acc   tensor(0.8210)\n",
      "\n",
      "Epoch 52/999:\n",
      "train loss  tensor(0.4210, dtype=torch.float64)\n",
      "train acc   tensor(0.8187)\n",
      "\n",
      "Epoch 53/999:\n",
      "train loss  tensor(0.4198, dtype=torch.float64)\n",
      "train acc   tensor(0.8237)\n",
      "\n",
      "Epoch 54/999:\n",
      "train loss  tensor(0.4165, dtype=torch.float64)\n",
      "train acc   tensor(0.8242)\n",
      "\n",
      "Epoch 55/999:\n",
      "train loss  tensor(0.4144, dtype=torch.float64)\n",
      "train acc   tensor(0.8228)\n",
      "\n",
      "Epoch 56/999:\n",
      "train loss  tensor(0.4134, dtype=torch.float64)\n",
      "train acc   tensor(0.8207)\n",
      "\n",
      "Epoch 57/999:\n",
      "train loss  tensor(0.4118, dtype=torch.float64)\n",
      "train acc   tensor(0.8231)\n",
      "\n",
      "Epoch 58/999:\n",
      "train loss  tensor(0.4106, dtype=torch.float64)\n",
      "train acc   tensor(0.8231)\n",
      "\n",
      "Epoch 59/999:\n",
      "train loss  tensor(0.4089, dtype=torch.float64)\n",
      "train acc   tensor(0.8231)\n",
      "\n",
      "Epoch 60/999:\n",
      "train loss  tensor(0.4076, dtype=torch.float64)\n",
      "train acc   tensor(0.8234)\n",
      "\n",
      "Epoch 61/999:\n",
      "train loss  tensor(0.4056, dtype=torch.float64)\n",
      "train acc   tensor(0.8234)\n",
      "\n",
      "Epoch 62/999:\n",
      "train loss  tensor(0.4030, dtype=torch.float64)\n",
      "train acc   tensor(0.8239)\n",
      "\n",
      "Epoch 63/999:\n",
      "train loss  tensor(0.4011, dtype=torch.float64)\n",
      "train acc   tensor(0.8239)\n",
      "\n",
      "Epoch 64/999:\n",
      "train loss  tensor(0.4000, dtype=torch.float64)\n",
      "train acc   tensor(0.8251)\n",
      "\n",
      "Epoch 65/999:\n",
      "train loss  tensor(0.3978, dtype=torch.float64)\n",
      "train acc   tensor(0.8257)\n",
      "\n",
      "Epoch 66/999:\n",
      "train loss  tensor(0.3978, dtype=torch.float64)\n",
      "train acc   tensor(0.8269)\n",
      "\n",
      "Epoch 67/999:\n",
      "train loss  tensor(0.3959, dtype=torch.float64)\n",
      "train acc   tensor(0.8275)\n",
      "\n",
      "Epoch 68/999:\n",
      "train loss  tensor(0.3946, dtype=torch.float64)\n",
      "train acc   tensor(0.8278)\n",
      "\n",
      "Epoch 69/999:\n",
      "train loss  tensor(0.3938, dtype=torch.float64)\n",
      "train acc   tensor(0.8278)\n",
      "\n",
      "Epoch 70/999:\n",
      "train loss  tensor(0.3921, dtype=torch.float64)\n",
      "train acc   tensor(0.8278)\n",
      "\n",
      "Epoch 71/999:\n",
      "train loss  tensor(0.3906, dtype=torch.float64)\n",
      "train acc   tensor(0.8360)\n",
      "\n",
      "Epoch 72/999:\n",
      "train loss  tensor(0.3888, dtype=torch.float64)\n",
      "train acc   tensor(0.8357)\n",
      "\n",
      "Epoch 73/999:\n",
      "train loss  tensor(0.3876, dtype=torch.float64)\n",
      "train acc   tensor(0.8357)\n",
      "\n",
      "Epoch 74/999:\n",
      "train loss  tensor(0.3856, dtype=torch.float64)\n",
      "train acc   tensor(0.8357)\n",
      "\n",
      "Epoch 75/999:\n",
      "train loss  tensor(0.3847, dtype=torch.float64)\n",
      "train acc   tensor(0.8360)\n",
      "\n",
      "Epoch 76/999:\n",
      "train loss  tensor(0.3829, dtype=torch.float64)\n",
      "train acc   tensor(0.8430)\n",
      "\n",
      "Epoch 77/999:\n",
      "train loss  tensor(0.3817, dtype=torch.float64)\n",
      "train acc   tensor(0.8418)\n",
      "\n",
      "Epoch 78/999:\n",
      "train loss  tensor(0.3811, dtype=torch.float64)\n",
      "train acc   tensor(0.8436)\n",
      "\n",
      "Epoch 79/999:\n",
      "train loss  tensor(0.3809, dtype=torch.float64)\n",
      "train acc   tensor(0.8433)\n",
      "\n",
      "Epoch 80/999:\n",
      "train loss  tensor(0.3791, dtype=torch.float64)\n",
      "train acc   tensor(0.8436)\n",
      "\n",
      "Epoch 81/999:\n",
      "train loss  tensor(0.3776, dtype=torch.float64)\n",
      "train acc   tensor(0.8436)\n",
      "\n",
      "Epoch 82/999:\n",
      "train loss  tensor(0.3756, dtype=torch.float64)\n",
      "train acc   tensor(0.8436)\n",
      "\n",
      "Epoch 83/999:\n",
      "train loss  tensor(0.3742, dtype=torch.float64)\n",
      "train acc   tensor(0.8442)\n",
      "\n",
      "Epoch 84/999:\n",
      "train loss  tensor(0.3741, dtype=torch.float64)\n",
      "train acc   tensor(0.8439)\n",
      "\n",
      "Epoch 85/999:\n",
      "train loss  tensor(0.3737, dtype=torch.float64)\n",
      "train acc   tensor(0.8436)\n",
      "\n",
      "Epoch 86/999:\n",
      "train loss  tensor(0.3727, dtype=torch.float64)\n",
      "train acc   tensor(0.8433)\n",
      "\n",
      "Epoch 87/999:\n",
      "train loss  tensor(0.3733, dtype=torch.float64)\n",
      "train acc   tensor(0.8363)\n",
      "\n",
      "Epoch 88/999:\n",
      "train loss  tensor(0.3718, dtype=torch.float64)\n",
      "train acc   tensor(0.8460)\n",
      "\n",
      "Epoch 89/999:\n",
      "train loss  tensor(0.3708, dtype=torch.float64)\n",
      "train acc   tensor(0.8465)\n",
      "\n",
      "Epoch 90/999:\n",
      "train loss  tensor(0.3705, dtype=torch.float64)\n",
      "train acc   tensor(0.8468)\n",
      "\n",
      "Epoch 91/999:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss  tensor(0.3699, dtype=torch.float64)\n",
      "train acc   tensor(0.8480)\n",
      "\n",
      "Epoch 92/999:\n",
      "train loss  tensor(0.3691, dtype=torch.float64)\n",
      "train acc   tensor(0.8483)\n",
      "\n",
      "Epoch 93/999:\n",
      "train loss  tensor(0.3686, dtype=torch.float64)\n",
      "train acc   tensor(0.8483)\n",
      "\n",
      "Epoch 94/999:\n",
      "train loss  tensor(0.3677, dtype=torch.float64)\n",
      "train acc   tensor(0.8486)\n",
      "\n",
      "Epoch 95/999:\n",
      "train loss  tensor(0.3665, dtype=torch.float64)\n",
      "train acc   tensor(0.8483)\n",
      "\n",
      "Epoch 96/999:\n",
      "train loss  tensor(0.3656, dtype=torch.float64)\n",
      "train acc   tensor(0.8486)\n",
      "\n",
      "Epoch 97/999:\n",
      "train loss  tensor(0.3646, dtype=torch.float64)\n",
      "train acc   tensor(0.8489)\n",
      "\n",
      "Epoch 98/999:\n",
      "train loss  tensor(0.3640, dtype=torch.float64)\n",
      "train acc   tensor(0.8492)\n",
      "\n",
      "Epoch 99/999:\n",
      "train loss  tensor(0.3629, dtype=torch.float64)\n",
      "train acc   tensor(0.8489)\n",
      "\n",
      "Epoch 100/999:\n",
      "train loss  tensor(0.3624, dtype=torch.float64)\n",
      "train acc   tensor(0.8480)\n",
      "\n",
      "Epoch 101/999:\n",
      "train loss  tensor(0.3614, dtype=torch.float64)\n",
      "train acc   tensor(0.8501)\n",
      "\n",
      "Epoch 102/999:\n",
      "train loss  tensor(0.3607, dtype=torch.float64)\n",
      "train acc   tensor(0.8501)\n",
      "\n",
      "Epoch 103/999:\n",
      "train loss  tensor(0.3592, dtype=torch.float64)\n",
      "train acc   tensor(0.8518)\n",
      "\n",
      "Epoch 104/999:\n",
      "train loss  tensor(0.3581, dtype=torch.float64)\n",
      "train acc   tensor(0.8506)\n",
      "\n",
      "Epoch 105/999:\n",
      "train loss  tensor(0.3575, dtype=torch.float64)\n",
      "train acc   tensor(0.8524)\n",
      "\n",
      "Epoch 106/999:\n",
      "train loss  tensor(0.3572, dtype=torch.float64)\n",
      "train acc   tensor(0.8542)\n",
      "\n",
      "Epoch 107/999:\n",
      "train loss  tensor(0.3559, dtype=torch.float64)\n",
      "train acc   tensor(0.8545)\n",
      "\n",
      "Epoch 108/999:\n",
      "train loss  tensor(0.3542, dtype=torch.float64)\n",
      "train acc   tensor(0.8550)\n",
      "\n",
      "Epoch 109/999:\n",
      "train loss  tensor(0.3546, dtype=torch.float64)\n",
      "train acc   tensor(0.8548)\n",
      "\n",
      "Epoch 110/999:\n",
      "train loss  tensor(0.3548, dtype=torch.float64)\n",
      "train acc   tensor(0.8530)\n",
      "\n",
      "Epoch 111/999:\n",
      "train loss  tensor(0.3537, dtype=torch.float64)\n",
      "train acc   tensor(0.8542)\n",
      "\n",
      "Epoch 112/999:\n",
      "train loss  tensor(0.3529, dtype=torch.float64)\n",
      "train acc   tensor(0.8533)\n",
      "\n",
      "Epoch 113/999:\n",
      "train loss  tensor(0.3517, dtype=torch.float64)\n",
      "train acc   tensor(0.8545)\n",
      "\n",
      "Epoch 114/999:\n",
      "train loss  tensor(0.3518, dtype=torch.float64)\n",
      "train acc   tensor(0.8539)\n",
      "\n",
      "Epoch 115/999:\n",
      "train loss  tensor(0.3515, dtype=torch.float64)\n",
      "train acc   tensor(0.8539)\n",
      "\n",
      "Epoch 116/999:\n",
      "train loss  tensor(0.3512, dtype=torch.float64)\n",
      "train acc   tensor(0.8548)\n",
      "\n",
      "Epoch 117/999:\n",
      "train loss  tensor(0.3507, dtype=torch.float64)\n",
      "train acc   tensor(0.8553)\n",
      "\n",
      "Epoch 118/999:\n",
      "train loss  tensor(0.3495, dtype=torch.float64)\n",
      "train acc   tensor(0.8553)\n",
      "\n",
      "Epoch 119/999:\n",
      "train loss  tensor(0.3487, dtype=torch.float64)\n",
      "train acc   tensor(0.8545)\n",
      "\n",
      "Epoch 120/999:\n",
      "train loss  tensor(0.3484, dtype=torch.float64)\n",
      "train acc   tensor(0.8556)\n",
      "\n",
      "Epoch 121/999:\n",
      "train loss  tensor(0.3472, dtype=torch.float64)\n",
      "train acc   tensor(0.8559)\n",
      "\n",
      "Epoch 122/999:\n",
      "train loss  tensor(0.3466, dtype=torch.float64)\n",
      "train acc   tensor(0.8536)\n",
      "\n",
      "Epoch 123/999:\n",
      "train loss  tensor(0.3458, dtype=torch.float64)\n",
      "train acc   tensor(0.8542)\n",
      "\n",
      "Epoch 124/999:\n",
      "train loss  tensor(0.3454, dtype=torch.float64)\n",
      "train acc   tensor(0.8548)\n",
      "\n",
      "Epoch 125/999:\n",
      "train loss  tensor(0.3460, dtype=torch.float64)\n",
      "train acc   tensor(0.8553)\n",
      "\n",
      "Epoch 126/999:\n",
      "train loss  tensor(0.3458, dtype=torch.float64)\n",
      "train acc   tensor(0.8548)\n",
      "\n",
      "Epoch 127/999:\n",
      "train loss  tensor(0.3454, dtype=torch.float64)\n",
      "train acc   tensor(0.8550)\n",
      "\n",
      "Epoch 128/999:\n",
      "train loss  tensor(0.3448, dtype=torch.float64)\n",
      "train acc   tensor(0.8550)\n",
      "\n",
      "Epoch 129/999:\n",
      "train loss  tensor(0.3442, dtype=torch.float64)\n",
      "train acc   tensor(0.8553)\n",
      "\n",
      "Epoch 130/999:\n",
      "train loss  tensor(0.3437, dtype=torch.float64)\n",
      "train acc   tensor(0.8562)\n",
      "\n",
      "Epoch 131/999:\n",
      "train loss  tensor(0.3432, dtype=torch.float64)\n",
      "train acc   tensor(0.8565)\n",
      "\n",
      "Epoch 132/999:\n",
      "train loss  tensor(0.3424, dtype=torch.float64)\n",
      "train acc   tensor(0.8571)\n",
      "\n",
      "Epoch 133/999:\n",
      "train loss  tensor(0.3423, dtype=torch.float64)\n",
      "train acc   tensor(0.8574)\n",
      "\n",
      "Epoch 134/999:\n",
      "train loss  tensor(0.3421, dtype=torch.float64)\n",
      "train acc   tensor(0.8574)\n",
      "\n",
      "Epoch 135/999:\n",
      "train loss  tensor(0.3417, dtype=torch.float64)\n",
      "train acc   tensor(0.8562)\n",
      "\n",
      "Epoch 136/999:\n",
      "train loss  tensor(0.3408, dtype=torch.float64)\n",
      "train acc   tensor(0.8565)\n",
      "\n",
      "Epoch 137/999:\n",
      "train loss  tensor(0.3405, dtype=torch.float64)\n",
      "train acc   tensor(0.8562)\n",
      "\n",
      "Epoch 138/999:\n",
      "train loss  tensor(0.3397, dtype=torch.float64)\n",
      "train acc   tensor(0.8565)\n",
      "\n",
      "Epoch 139/999:\n",
      "train loss  tensor(0.3388, dtype=torch.float64)\n",
      "train acc   tensor(0.8565)\n",
      "\n",
      "Epoch 140/999:\n",
      "train loss  tensor(0.3398, dtype=torch.float64)\n",
      "train acc   tensor(0.8571)\n",
      "\n",
      "Epoch 141/999:\n",
      "train loss  tensor(0.3384, dtype=torch.float64)\n",
      "train acc   tensor(0.8580)\n",
      "\n",
      "Epoch 142/999:\n",
      "train loss  tensor(0.3378, dtype=torch.float64)\n",
      "train acc   tensor(0.8577)\n",
      "\n",
      "Epoch 143/999:\n",
      "train loss  tensor(0.3393, dtype=torch.float64)\n",
      "train acc   tensor(0.8583)\n",
      "\n",
      "Epoch 144/999:\n",
      "train loss  tensor(0.3393, dtype=torch.float64)\n",
      "train acc   tensor(0.8580)\n",
      "\n",
      "Epoch 145/999:\n",
      "train loss  tensor(0.3392, dtype=torch.float64)\n",
      "train acc   tensor(0.8577)\n",
      "\n",
      "Epoch 146/999:\n",
      "train loss  tensor(0.3403, dtype=torch.float64)\n",
      "train acc   tensor(0.8592)\n",
      "\n",
      "Epoch 147/999:\n",
      "train loss  tensor(0.3398, dtype=torch.float64)\n",
      "train acc   tensor(0.8600)\n",
      "\n",
      "Epoch 148/999:\n",
      "train loss  tensor(0.3392, dtype=torch.float64)\n",
      "train acc   tensor(0.8600)\n",
      "\n",
      "Epoch 149/999:\n",
      "train loss  tensor(0.3390, dtype=torch.float64)\n",
      "train acc   tensor(0.8594)\n",
      "\n",
      "Epoch 150/999:\n",
      "train loss  tensor(0.3371, dtype=torch.float64)\n",
      "train acc   tensor(0.8603)\n",
      "\n",
      "Epoch 151/999:\n",
      "train loss  tensor(0.3364, dtype=torch.float64)\n",
      "train acc   tensor(0.8600)\n",
      "\n",
      "Epoch 152/999:\n",
      "train loss  tensor(0.3358, dtype=torch.float64)\n",
      "train acc   tensor(0.8618)\n",
      "\n",
      "Epoch 153/999:\n",
      "train loss  tensor(0.3352, dtype=torch.float64)\n",
      "train acc   tensor(0.8633)\n",
      "\n",
      "Epoch 154/999:\n",
      "train loss  tensor(0.3345, dtype=torch.float64)\n",
      "train acc   tensor(0.8627)\n",
      "\n",
      "Epoch 155/999:\n",
      "train loss  tensor(0.3329, dtype=torch.float64)\n",
      "train acc   tensor(0.8638)\n",
      "\n",
      "Epoch 156/999:\n",
      "train loss  tensor(0.3332, dtype=torch.float64)\n",
      "train acc   tensor(0.8665)\n",
      "\n",
      "Epoch 157/999:\n",
      "train loss  tensor(0.3326, dtype=torch.float64)\n",
      "train acc   tensor(0.8641)\n",
      "\n",
      "Epoch 158/999:\n",
      "train loss  tensor(0.3314, dtype=torch.float64)\n",
      "train acc   tensor(0.8665)\n",
      "\n",
      "Epoch 159/999:\n",
      "train loss  tensor(0.3308, dtype=torch.float64)\n",
      "train acc   tensor(0.8677)\n",
      "\n",
      "Epoch 160/999:\n",
      "train loss  tensor(0.3306, dtype=torch.float64)\n",
      "train acc   tensor(0.8683)\n",
      "\n",
      "Epoch 161/999:\n",
      "train loss  tensor(0.3301, dtype=torch.float64)\n",
      "train acc   tensor(0.8671)\n",
      "\n",
      "Epoch 162/999:\n",
      "train loss  tensor(0.3301, dtype=torch.float64)\n",
      "train acc   tensor(0.8662)\n",
      "\n",
      "Epoch 163/999:\n",
      "train loss  tensor(0.3291, dtype=torch.float64)\n",
      "train acc   tensor(0.8659)\n",
      "\n",
      "Epoch 164/999:\n",
      "train loss  tensor(0.3290, dtype=torch.float64)\n",
      "train acc   tensor(0.8659)\n",
      "\n",
      "Epoch 165/999:\n",
      "train loss  tensor(0.3281, dtype=torch.float64)\n",
      "train acc   tensor(0.8680)\n",
      "\n",
      "Epoch 166/999:\n",
      "train loss  tensor(0.3281, dtype=torch.float64)\n",
      "train acc   tensor(0.8688)\n",
      "\n",
      "Epoch 167/999:\n",
      "train loss  tensor(0.3275, dtype=torch.float64)\n",
      "train acc   tensor(0.8691)\n",
      "\n",
      "Epoch 168/999:\n",
      "train loss  tensor(0.3274, dtype=torch.float64)\n",
      "train acc   tensor(0.8685)\n",
      "\n",
      "Epoch 169/999:\n",
      "train loss  tensor(0.3270, dtype=torch.float64)\n",
      "train acc   tensor(0.8691)\n",
      "\n",
      "Epoch 170/999:\n",
      "train loss  tensor(0.3266, dtype=torch.float64)\n",
      "train acc   tensor(0.8691)\n",
      "\n",
      "Epoch 171/999:\n",
      "train loss  tensor(0.3267, dtype=torch.float64)\n",
      "train acc   tensor(0.8700)\n",
      "\n",
      "Epoch 172/999:\n",
      "train loss  tensor(0.3267, dtype=torch.float64)\n",
      "train acc   tensor(0.8700)\n",
      "\n",
      "Epoch 173/999:\n",
      "train loss  tensor(0.3269, dtype=torch.float64)\n",
      "train acc   tensor(0.8706)\n",
      "\n",
      "Epoch 174/999:\n",
      "train loss  tensor(0.3261, dtype=torch.float64)\n",
      "train acc   tensor(0.8718)\n",
      "\n",
      "Epoch 175/999:\n",
      "train loss  tensor(0.3249, dtype=torch.float64)\n",
      "train acc   tensor(0.8735)\n",
      "\n",
      "Epoch 176/999:\n",
      "train loss  tensor(0.3253, dtype=torch.float64)\n",
      "train acc   tensor(0.8732)\n",
      "\n",
      "Epoch 177/999:\n",
      "train loss  tensor(0.3248, dtype=torch.float64)\n",
      "train acc   tensor(0.8732)\n",
      "\n",
      "Epoch 178/999:\n",
      "train loss  tensor(0.3242, dtype=torch.float64)\n",
      "train acc   tensor(0.8721)\n",
      "\n",
      "Epoch 179/999:\n",
      "train loss  tensor(0.3238, dtype=torch.float64)\n",
      "train acc   tensor(0.8735)\n",
      "\n",
      "Epoch 180/999:\n",
      "train loss  tensor(0.3233, dtype=torch.float64)\n",
      "train acc   tensor(0.8727)\n",
      "\n",
      "Epoch 181/999:\n",
      "train loss  tensor(0.3241, dtype=torch.float64)\n",
      "train acc   tensor(0.8724)\n",
      "\n",
      "Epoch 182/999:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss  tensor(0.3220, dtype=torch.float64)\n",
      "train acc   tensor(0.8735)\n",
      "\n",
      "Epoch 183/999:\n",
      "train loss  tensor(0.3220, dtype=torch.float64)\n",
      "train acc   tensor(0.8738)\n",
      "\n",
      "Epoch 184/999:\n",
      "train loss  tensor(0.3215, dtype=torch.float64)\n",
      "train acc   tensor(0.8732)\n",
      "\n",
      "Epoch 185/999:\n",
      "train loss  tensor(0.3227, dtype=torch.float64)\n",
      "train acc   tensor(0.8735)\n",
      "\n",
      "Epoch 186/999:\n",
      "train loss  tensor(0.3227, dtype=torch.float64)\n",
      "train acc   tensor(0.8732)\n",
      "\n",
      "Epoch 187/999:\n",
      "train loss  tensor(0.3222, dtype=torch.float64)\n",
      "train acc   tensor(0.8785)\n",
      "\n",
      "Epoch 188/999:\n",
      "train loss  tensor(0.3223, dtype=torch.float64)\n",
      "train acc   tensor(0.8791)\n",
      "\n",
      "Epoch 189/999:\n",
      "train loss  tensor(0.3219, dtype=torch.float64)\n",
      "train acc   tensor(0.8800)\n",
      "\n",
      "Epoch 190/999:\n",
      "train loss  tensor(0.3216, dtype=torch.float64)\n",
      "train acc   tensor(0.8800)\n",
      "\n",
      "Epoch 191/999:\n",
      "train loss  tensor(0.3212, dtype=torch.float64)\n",
      "train acc   tensor(0.8800)\n",
      "\n",
      "Epoch 192/999:\n",
      "train loss  tensor(0.3207, dtype=torch.float64)\n",
      "train acc   tensor(0.8803)\n",
      "\n",
      "Epoch 193/999:\n",
      "train loss  tensor(0.3197, dtype=torch.float64)\n",
      "train acc   tensor(0.8794)\n",
      "\n",
      "Epoch 194/999:\n",
      "train loss  tensor(0.3190, dtype=torch.float64)\n",
      "train acc   tensor(0.8882)\n",
      "\n",
      "Epoch 195/999:\n",
      "train loss  tensor(0.3189, dtype=torch.float64)\n",
      "train acc   tensor(0.8882)\n",
      "\n",
      "Epoch 196/999:\n",
      "train loss  tensor(0.3189, dtype=torch.float64)\n",
      "train acc   tensor(0.8862)\n",
      "\n",
      "Epoch 197/999:\n",
      "train loss  tensor(0.3183, dtype=torch.float64)\n",
      "train acc   tensor(0.8870)\n",
      "\n",
      "Epoch 198/999:\n",
      "train loss  tensor(0.3187, dtype=torch.float64)\n",
      "train acc   tensor(0.8859)\n",
      "\n",
      "Epoch 199/999:\n",
      "train loss  tensor(0.3186, dtype=torch.float64)\n",
      "train acc   tensor(0.8838)\n",
      "\n",
      "Epoch 200/999:\n",
      "train loss  tensor(0.3177, dtype=torch.float64)\n",
      "train acc   tensor(0.8859)\n",
      "\n",
      "Epoch 201/999:\n",
      "train loss  tensor(0.3174, dtype=torch.float64)\n",
      "train acc   tensor(0.8856)\n",
      "\n",
      "Epoch 202/999:\n",
      "train loss  tensor(0.3169, dtype=torch.float64)\n",
      "train acc   tensor(0.8853)\n",
      "\n",
      "Epoch 203/999:\n",
      "train loss  tensor(0.3171, dtype=torch.float64)\n",
      "train acc   tensor(0.8867)\n",
      "\n",
      "Epoch 204/999:\n",
      "train loss  tensor(0.3164, dtype=torch.float64)\n",
      "train acc   tensor(0.8870)\n",
      "\n",
      "Epoch 205/999:\n",
      "train loss  tensor(0.3166, dtype=torch.float64)\n",
      "train acc   tensor(0.8864)\n",
      "\n",
      "Epoch 206/999:\n",
      "train loss  tensor(0.3158, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 207/999:\n",
      "train loss  tensor(0.3157, dtype=torch.float64)\n",
      "train acc   tensor(0.8879)\n",
      "\n",
      "Epoch 208/999:\n",
      "train loss  tensor(0.3158, dtype=torch.float64)\n",
      "train acc   tensor(0.8879)\n",
      "\n",
      "Epoch 209/999:\n",
      "train loss  tensor(0.3156, dtype=torch.float64)\n",
      "train acc   tensor(0.8876)\n",
      "\n",
      "Epoch 210/999:\n",
      "train loss  tensor(0.3150, dtype=torch.float64)\n",
      "train acc   tensor(0.8870)\n",
      "\n",
      "Epoch 211/999:\n",
      "train loss  tensor(0.3140, dtype=torch.float64)\n",
      "train acc   tensor(0.8873)\n",
      "\n",
      "Epoch 212/999:\n",
      "train loss  tensor(0.3139, dtype=torch.float64)\n",
      "train acc   tensor(0.8873)\n",
      "\n",
      "Epoch 213/999:\n",
      "train loss  tensor(0.3144, dtype=torch.float64)\n",
      "train acc   tensor(0.8873)\n",
      "\n",
      "Epoch 214/999:\n",
      "train loss  tensor(0.3142, dtype=torch.float64)\n",
      "train acc   tensor(0.8876)\n",
      "\n",
      "Epoch 215/999:\n",
      "train loss  tensor(0.3147, dtype=torch.float64)\n",
      "train acc   tensor(0.8879)\n",
      "\n",
      "Epoch 216/999:\n",
      "train loss  tensor(0.3139, dtype=torch.float64)\n",
      "train acc   tensor(0.8879)\n",
      "\n",
      "Epoch 217/999:\n",
      "train loss  tensor(0.3144, dtype=torch.float64)\n",
      "train acc   tensor(0.8876)\n",
      "\n",
      "Epoch 218/999:\n",
      "train loss  tensor(0.3149, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 219/999:\n",
      "train loss  tensor(0.3151, dtype=torch.float64)\n",
      "train acc   tensor(0.8876)\n",
      "\n",
      "Epoch 220/999:\n",
      "train loss  tensor(0.3140, dtype=torch.float64)\n",
      "train acc   tensor(0.8873)\n",
      "\n",
      "Epoch 221/999:\n",
      "train loss  tensor(0.3130, dtype=torch.float64)\n",
      "train acc   tensor(0.8873)\n",
      "\n",
      "Epoch 222/999:\n",
      "train loss  tensor(0.3128, dtype=torch.float64)\n",
      "train acc   tensor(0.8876)\n",
      "\n",
      "Epoch 223/999:\n",
      "train loss  tensor(0.3126, dtype=torch.float64)\n",
      "train acc   tensor(0.8879)\n",
      "\n",
      "Epoch 224/999:\n",
      "train loss  tensor(0.3118, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 225/999:\n",
      "train loss  tensor(0.3120, dtype=torch.float64)\n",
      "train acc   tensor(0.8879)\n",
      "\n",
      "Epoch 226/999:\n",
      "train loss  tensor(0.3115, dtype=torch.float64)\n",
      "train acc   tensor(0.8882)\n",
      "\n",
      "Epoch 227/999:\n",
      "train loss  tensor(0.3111, dtype=torch.float64)\n",
      "train acc   tensor(0.8882)\n",
      "\n",
      "Epoch 228/999:\n",
      "train loss  tensor(0.3119, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 229/999:\n",
      "train loss  tensor(0.3119, dtype=torch.float64)\n",
      "train acc   tensor(0.8788)\n",
      "\n",
      "Epoch 230/999:\n",
      "train loss  tensor(0.3109, dtype=torch.float64)\n",
      "train acc   tensor(0.8791)\n",
      "\n",
      "Epoch 231/999:\n",
      "train loss  tensor(0.3106, dtype=torch.float64)\n",
      "train acc   tensor(0.8782)\n",
      "\n",
      "Epoch 232/999:\n",
      "train loss  tensor(0.3103, dtype=torch.float64)\n",
      "train acc   tensor(0.8870)\n",
      "\n",
      "Epoch 233/999:\n",
      "train loss  tensor(0.3102, dtype=torch.float64)\n",
      "train acc   tensor(0.8864)\n",
      "\n",
      "Epoch 234/999:\n",
      "train loss  tensor(0.3101, dtype=torch.float64)\n",
      "train acc   tensor(0.8862)\n",
      "\n",
      "Epoch 235/999:\n",
      "train loss  tensor(0.3097, dtype=torch.float64)\n",
      "train acc   tensor(0.8870)\n",
      "\n",
      "Epoch 236/999:\n",
      "train loss  tensor(0.3093, dtype=torch.float64)\n",
      "train acc   tensor(0.8876)\n",
      "\n",
      "Epoch 237/999:\n",
      "train loss  tensor(0.3089, dtype=torch.float64)\n",
      "train acc   tensor(0.8873)\n",
      "\n",
      "Epoch 238/999:\n",
      "train loss  tensor(0.3087, dtype=torch.float64)\n",
      "train acc   tensor(0.8870)\n",
      "\n",
      "Epoch 239/999:\n",
      "train loss  tensor(0.3084, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 240/999:\n",
      "train loss  tensor(0.3079, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 241/999:\n",
      "train loss  tensor(0.3067, dtype=torch.float64)\n",
      "train acc   tensor(0.8888)\n",
      "\n",
      "Epoch 242/999:\n",
      "train loss  tensor(0.3064, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 243/999:\n",
      "train loss  tensor(0.3061, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 244/999:\n",
      "train loss  tensor(0.3062, dtype=torch.float64)\n",
      "train acc   tensor(0.8882)\n",
      "\n",
      "Epoch 245/999:\n",
      "train loss  tensor(0.3059, dtype=torch.float64)\n",
      "train acc   tensor(0.8882)\n",
      "\n",
      "Epoch 246/999:\n",
      "train loss  tensor(0.3060, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 247/999:\n",
      "train loss  tensor(0.3057, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 248/999:\n",
      "train loss  tensor(0.3047, dtype=torch.float64)\n",
      "train acc   tensor(0.8882)\n",
      "\n",
      "Epoch 249/999:\n",
      "train loss  tensor(0.3041, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 250/999:\n",
      "train loss  tensor(0.3044, dtype=torch.float64)\n",
      "train acc   tensor(0.8882)\n",
      "\n",
      "Epoch 251/999:\n",
      "train loss  tensor(0.3047, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 252/999:\n",
      "train loss  tensor(0.3051, dtype=torch.float64)\n",
      "train acc   tensor(0.8850)\n",
      "\n",
      "Epoch 253/999:\n",
      "train loss  tensor(0.3039, dtype=torch.float64)\n",
      "train acc   tensor(0.8862)\n",
      "\n",
      "Epoch 254/999:\n",
      "train loss  tensor(0.3034, dtype=torch.float64)\n",
      "train acc   tensor(0.8862)\n",
      "\n",
      "Epoch 255/999:\n",
      "train loss  tensor(0.3035, dtype=torch.float64)\n",
      "train acc   tensor(0.8862)\n",
      "\n",
      "Epoch 256/999:\n",
      "train loss  tensor(0.3040, dtype=torch.float64)\n",
      "train acc   tensor(0.8864)\n",
      "\n",
      "Epoch 257/999:\n",
      "train loss  tensor(0.3038, dtype=torch.float64)\n",
      "train acc   tensor(0.8864)\n",
      "\n",
      "Epoch 258/999:\n",
      "train loss  tensor(0.3029, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 259/999:\n",
      "train loss  tensor(0.3029, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 260/999:\n",
      "train loss  tensor(0.3029, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 261/999:\n",
      "train loss  tensor(0.3025, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 262/999:\n",
      "train loss  tensor(0.3020, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 263/999:\n",
      "train loss  tensor(0.3020, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 264/999:\n",
      "train loss  tensor(0.3016, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 265/999:\n",
      "train loss  tensor(0.3012, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 266/999:\n",
      "train loss  tensor(0.3007, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 267/999:\n",
      "train loss  tensor(0.3002, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 268/999:\n",
      "train loss  tensor(0.3000, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 269/999:\n",
      "train loss  tensor(0.3000, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 270/999:\n",
      "train loss  tensor(0.2994, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 271/999:\n",
      "train loss  tensor(0.2994, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 272/999:\n",
      "train loss  tensor(0.2987, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 273/999:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss  tensor(0.2988, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 274/999:\n",
      "train loss  tensor(0.2987, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 275/999:\n",
      "train loss  tensor(0.2985, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 276/999:\n",
      "train loss  tensor(0.2986, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 277/999:\n",
      "train loss  tensor(0.2982, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 278/999:\n",
      "train loss  tensor(0.2981, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 279/999:\n",
      "train loss  tensor(0.2978, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 280/999:\n",
      "train loss  tensor(0.2978, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 281/999:\n",
      "train loss  tensor(0.2971, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 282/999:\n",
      "train loss  tensor(0.2972, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 283/999:\n",
      "train loss  tensor(0.2963, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 284/999:\n",
      "train loss  tensor(0.2968, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 285/999:\n",
      "train loss  tensor(0.2969, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 286/999:\n",
      "train loss  tensor(0.2973, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 287/999:\n",
      "train loss  tensor(0.2970, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 288/999:\n",
      "train loss  tensor(0.2962, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 289/999:\n",
      "train loss  tensor(0.2963, dtype=torch.float64)\n",
      "train acc   tensor(0.8879)\n",
      "\n",
      "Epoch 290/999:\n",
      "train loss  tensor(0.2968, dtype=torch.float64)\n",
      "train acc   tensor(0.8876)\n",
      "\n",
      "Epoch 291/999:\n",
      "train loss  tensor(0.2965, dtype=torch.float64)\n",
      "train acc   tensor(0.8879)\n",
      "\n",
      "Epoch 292/999:\n",
      "train loss  tensor(0.2957, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 293/999:\n",
      "train loss  tensor(0.2955, dtype=torch.float64)\n",
      "train acc   tensor(0.8882)\n",
      "\n",
      "Epoch 294/999:\n",
      "train loss  tensor(0.2956, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 295/999:\n",
      "train loss  tensor(0.2955, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 296/999:\n",
      "train loss  tensor(0.2951, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 297/999:\n",
      "train loss  tensor(0.2952, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 298/999:\n",
      "train loss  tensor(0.2947, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 299/999:\n",
      "train loss  tensor(0.2949, dtype=torch.float64)\n",
      "train acc   tensor(0.8888)\n",
      "\n",
      "Epoch 300/999:\n",
      "train loss  tensor(0.2954, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 301/999:\n",
      "train loss  tensor(0.2946, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 302/999:\n",
      "train loss  tensor(0.2946, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 303/999:\n",
      "train loss  tensor(0.2947, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 304/999:\n",
      "train loss  tensor(0.2943, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 305/999:\n",
      "train loss  tensor(0.2939, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 306/999:\n",
      "train loss  tensor(0.2940, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 307/999:\n",
      "train loss  tensor(0.2938, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 308/999:\n",
      "train loss  tensor(0.2939, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 309/999:\n",
      "train loss  tensor(0.2941, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 310/999:\n",
      "train loss  tensor(0.2942, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 311/999:\n",
      "train loss  tensor(0.2940, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 312/999:\n",
      "train loss  tensor(0.2930, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 313/999:\n",
      "train loss  tensor(0.2930, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 314/999:\n",
      "train loss  tensor(0.2926, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 315/999:\n",
      "train loss  tensor(0.2927, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 316/999:\n",
      "train loss  tensor(0.2926, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 317/999:\n",
      "train loss  tensor(0.2923, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 318/999:\n",
      "train loss  tensor(0.2920, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 319/999:\n",
      "train loss  tensor(0.2915, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 320/999:\n",
      "train loss  tensor(0.2904, dtype=torch.float64)\n",
      "train acc   tensor(0.9020)\n",
      "\n",
      "Epoch 321/999:\n",
      "train loss  tensor(0.2906, dtype=torch.float64)\n",
      "train acc   tensor(0.9008)\n",
      "\n",
      "Epoch 322/999:\n",
      "train loss  tensor(0.2907, dtype=torch.float64)\n",
      "train acc   tensor(0.9011)\n",
      "\n",
      "Epoch 323/999:\n",
      "train loss  tensor(0.2904, dtype=torch.float64)\n",
      "train acc   tensor(0.9011)\n",
      "\n",
      "Epoch 324/999:\n",
      "train loss  tensor(0.2897, dtype=torch.float64)\n",
      "train acc   tensor(0.9008)\n",
      "\n",
      "Epoch 325/999:\n",
      "train loss  tensor(0.2892, dtype=torch.float64)\n",
      "train acc   tensor(0.9011)\n",
      "\n",
      "Epoch 326/999:\n",
      "train loss  tensor(0.2889, dtype=torch.float64)\n",
      "train acc   tensor(0.9017)\n",
      "\n",
      "Epoch 327/999:\n",
      "train loss  tensor(0.2887, dtype=torch.float64)\n",
      "train acc   tensor(0.9014)\n",
      "\n",
      "Epoch 328/999:\n",
      "train loss  tensor(0.2885, dtype=torch.float64)\n",
      "train acc   tensor(0.9014)\n",
      "\n",
      "Epoch 329/999:\n",
      "train loss  tensor(0.2887, dtype=torch.float64)\n",
      "train acc   tensor(0.9014)\n",
      "\n",
      "Epoch 330/999:\n",
      "train loss  tensor(0.2879, dtype=torch.float64)\n",
      "train acc   tensor(0.9005)\n",
      "\n",
      "Epoch 331/999:\n",
      "train loss  tensor(0.2898, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 332/999:\n",
      "train loss  tensor(0.2900, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 333/999:\n",
      "train loss  tensor(0.2893, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 334/999:\n",
      "train loss  tensor(0.2890, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 335/999:\n",
      "train loss  tensor(0.2888, dtype=torch.float64)\n",
      "train acc   tensor(0.8873)\n",
      "\n",
      "Epoch 336/999:\n",
      "train loss  tensor(0.2889, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 337/999:\n",
      "train loss  tensor(0.2890, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 338/999:\n",
      "train loss  tensor(0.2885, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 339/999:\n",
      "train loss  tensor(0.2891, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 340/999:\n",
      "train loss  tensor(0.2884, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 341/999:\n",
      "train loss  tensor(0.2881, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 342/999:\n",
      "train loss  tensor(0.2880, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 343/999:\n",
      "train loss  tensor(0.2883, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 344/999:\n",
      "train loss  tensor(0.2882, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 345/999:\n",
      "train loss  tensor(0.2888, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 346/999:\n",
      "train loss  tensor(0.2884, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 347/999:\n",
      "train loss  tensor(0.2885, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 348/999:\n",
      "train loss  tensor(0.2888, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 349/999:\n",
      "train loss  tensor(0.2889, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 350/999:\n",
      "train loss  tensor(0.2887, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 351/999:\n",
      "train loss  tensor(0.2882, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 352/999:\n",
      "train loss  tensor(0.2881, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 353/999:\n",
      "train loss  tensor(0.2878, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 354/999:\n",
      "train loss  tensor(0.2875, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 355/999:\n",
      "train loss  tensor(0.2885, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 356/999:\n",
      "train loss  tensor(0.2881, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 357/999:\n",
      "train loss  tensor(0.2879, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 358/999:\n",
      "train loss  tensor(0.2875, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 359/999:\n",
      "train loss  tensor(0.2875, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 360/999:\n",
      "train loss  tensor(0.2879, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 361/999:\n",
      "train loss  tensor(0.2876, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 362/999:\n",
      "train loss  tensor(0.2871, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 363/999:\n",
      "train loss  tensor(0.2873, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 364/999:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss  tensor(0.2881, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 365/999:\n",
      "train loss  tensor(0.2880, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 366/999:\n",
      "train loss  tensor(0.2883, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 367/999:\n",
      "train loss  tensor(0.2882, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 368/999:\n",
      "train loss  tensor(0.2874, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 369/999:\n",
      "train loss  tensor(0.2874, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 370/999:\n",
      "train loss  tensor(0.2875, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 371/999:\n",
      "train loss  tensor(0.2871, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 372/999:\n",
      "train loss  tensor(0.2870, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 373/999:\n",
      "train loss  tensor(0.2872, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 374/999:\n",
      "train loss  tensor(0.2868, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 375/999:\n",
      "train loss  tensor(0.2865, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 376/999:\n",
      "train loss  tensor(0.2862, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 377/999:\n",
      "train loss  tensor(0.2856, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 378/999:\n",
      "train loss  tensor(0.2858, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 379/999:\n",
      "train loss  tensor(0.2855, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 380/999:\n",
      "train loss  tensor(0.2850, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 381/999:\n",
      "train loss  tensor(0.2849, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 382/999:\n",
      "train loss  tensor(0.2852, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 383/999:\n",
      "train loss  tensor(0.2851, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 384/999:\n",
      "train loss  tensor(0.2850, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 385/999:\n",
      "train loss  tensor(0.2851, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 386/999:\n",
      "train loss  tensor(0.2853, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 387/999:\n",
      "train loss  tensor(0.2851, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 388/999:\n",
      "train loss  tensor(0.2848, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 389/999:\n",
      "train loss  tensor(0.2844, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 390/999:\n",
      "train loss  tensor(0.2843, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 391/999:\n",
      "train loss  tensor(0.2845, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 392/999:\n",
      "train loss  tensor(0.2844, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 393/999:\n",
      "train loss  tensor(0.2844, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 394/999:\n",
      "train loss  tensor(0.2844, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 395/999:\n",
      "train loss  tensor(0.2843, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 396/999:\n",
      "train loss  tensor(0.2841, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 397/999:\n",
      "train loss  tensor(0.2842, dtype=torch.float64)\n",
      "train acc   tensor(0.9005)\n",
      "\n",
      "Epoch 398/999:\n",
      "train loss  tensor(0.2842, dtype=torch.float64)\n",
      "train acc   tensor(0.8979)\n",
      "\n",
      "Epoch 399/999:\n",
      "train loss  tensor(0.2842, dtype=torch.float64)\n",
      "train acc   tensor(0.8976)\n",
      "\n",
      "Epoch 400/999:\n",
      "train loss  tensor(0.2841, dtype=torch.float64)\n",
      "train acc   tensor(0.8976)\n",
      "\n",
      "Epoch 401/999:\n",
      "train loss  tensor(0.2840, dtype=torch.float64)\n",
      "train acc   tensor(0.8979)\n",
      "\n",
      "Epoch 402/999:\n",
      "train loss  tensor(0.2837, dtype=torch.float64)\n",
      "train acc   tensor(0.8979)\n",
      "\n",
      "Epoch 403/999:\n",
      "train loss  tensor(0.2835, dtype=torch.float64)\n",
      "train acc   tensor(0.8979)\n",
      "\n",
      "Epoch 404/999:\n",
      "train loss  tensor(0.2839, dtype=torch.float64)\n",
      "train acc   tensor(0.8879)\n",
      "\n",
      "Epoch 405/999:\n",
      "train loss  tensor(0.2838, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 406/999:\n",
      "train loss  tensor(0.2835, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 407/999:\n",
      "train loss  tensor(0.2830, dtype=torch.float64)\n",
      "train acc   tensor(0.9002)\n",
      "\n",
      "Epoch 408/999:\n",
      "train loss  tensor(0.2833, dtype=torch.float64)\n",
      "train acc   tensor(0.9008)\n",
      "\n",
      "Epoch 409/999:\n",
      "train loss  tensor(0.2830, dtype=torch.float64)\n",
      "train acc   tensor(0.9038)\n",
      "\n",
      "Epoch 410/999:\n",
      "train loss  tensor(0.2829, dtype=torch.float64)\n",
      "train acc   tensor(0.9029)\n",
      "\n",
      "Epoch 411/999:\n",
      "train loss  tensor(0.2827, dtype=torch.float64)\n",
      "train acc   tensor(0.9029)\n",
      "\n",
      "Epoch 412/999:\n",
      "train loss  tensor(0.2824, dtype=torch.float64)\n",
      "train acc   tensor(0.9035)\n",
      "\n",
      "Epoch 413/999:\n",
      "train loss  tensor(0.2821, dtype=torch.float64)\n",
      "train acc   tensor(0.9035)\n",
      "\n",
      "Epoch 414/999:\n",
      "train loss  tensor(0.2826, dtype=torch.float64)\n",
      "train acc   tensor(0.9043)\n",
      "\n",
      "Epoch 415/999:\n",
      "train loss  tensor(0.2823, dtype=torch.float64)\n",
      "train acc   tensor(0.9046)\n",
      "\n",
      "Epoch 416/999:\n",
      "train loss  tensor(0.2823, dtype=torch.float64)\n",
      "train acc   tensor(0.9052)\n",
      "\n",
      "Epoch 417/999:\n",
      "train loss  tensor(0.2823, dtype=torch.float64)\n",
      "train acc   tensor(0.9049)\n",
      "\n",
      "Epoch 418/999:\n",
      "train loss  tensor(0.2822, dtype=torch.float64)\n",
      "train acc   tensor(0.9046)\n",
      "\n",
      "Epoch 419/999:\n",
      "train loss  tensor(0.2821, dtype=torch.float64)\n",
      "train acc   tensor(0.9046)\n",
      "\n",
      "Epoch 420/999:\n",
      "train loss  tensor(0.2820, dtype=torch.float64)\n",
      "train acc   tensor(0.9043)\n",
      "\n",
      "Epoch 421/999:\n",
      "train loss  tensor(0.2816, dtype=torch.float64)\n",
      "train acc   tensor(0.9046)\n",
      "\n",
      "Epoch 422/999:\n",
      "train loss  tensor(0.2814, dtype=torch.float64)\n",
      "train acc   tensor(0.9040)\n",
      "\n",
      "Epoch 423/999:\n",
      "train loss  tensor(0.2813, dtype=torch.float64)\n",
      "train acc   tensor(0.9040)\n",
      "\n",
      "Epoch 424/999:\n",
      "train loss  tensor(0.2815, dtype=torch.float64)\n",
      "train acc   tensor(0.9040)\n",
      "\n",
      "Epoch 425/999:\n",
      "train loss  tensor(0.2815, dtype=torch.float64)\n",
      "train acc   tensor(0.9043)\n",
      "\n",
      "Epoch 426/999:\n",
      "train loss  tensor(0.2812, dtype=torch.float64)\n",
      "train acc   tensor(0.9043)\n",
      "\n",
      "Epoch 427/999:\n",
      "train loss  tensor(0.2813, dtype=torch.float64)\n",
      "train acc   tensor(0.9043)\n",
      "\n",
      "Epoch 428/999:\n",
      "train loss  tensor(0.2813, dtype=torch.float64)\n",
      "train acc   tensor(0.9032)\n",
      "\n",
      "Epoch 429/999:\n",
      "train loss  tensor(0.2813, dtype=torch.float64)\n",
      "train acc   tensor(0.9032)\n",
      "\n",
      "Epoch 430/999:\n",
      "train loss  tensor(0.2810, dtype=torch.float64)\n",
      "train acc   tensor(0.9029)\n",
      "\n",
      "Epoch 431/999:\n",
      "train loss  tensor(0.2799, dtype=torch.float64)\n",
      "train acc   tensor(0.9029)\n",
      "\n",
      "Epoch 432/999:\n",
      "train loss  tensor(0.2798, dtype=torch.float64)\n",
      "train acc   tensor(0.9029)\n",
      "\n",
      "Epoch 433/999:\n",
      "train loss  tensor(0.2794, dtype=torch.float64)\n",
      "train acc   tensor(0.9026)\n",
      "\n",
      "Epoch 434/999:\n",
      "train loss  tensor(0.2795, dtype=torch.float64)\n",
      "train acc   tensor(0.9035)\n",
      "\n",
      "Epoch 435/999:\n",
      "train loss  tensor(0.2789, dtype=torch.float64)\n",
      "train acc   tensor(0.9035)\n",
      "\n",
      "Epoch 436/999:\n",
      "train loss  tensor(0.2791, dtype=torch.float64)\n",
      "train acc   tensor(0.9032)\n",
      "\n",
      "Epoch 437/999:\n",
      "train loss  tensor(0.2793, dtype=torch.float64)\n",
      "train acc   tensor(0.9032)\n",
      "\n",
      "Epoch 438/999:\n",
      "train loss  tensor(0.2791, dtype=torch.float64)\n",
      "train acc   tensor(0.9040)\n",
      "\n",
      "Epoch 439/999:\n",
      "train loss  tensor(0.2792, dtype=torch.float64)\n",
      "train acc   tensor(0.9038)\n",
      "\n",
      "Epoch 440/999:\n",
      "train loss  tensor(0.2790, dtype=torch.float64)\n",
      "train acc   tensor(0.9049)\n",
      "\n",
      "Epoch 441/999:\n",
      "train loss  tensor(0.2793, dtype=torch.float64)\n",
      "train acc   tensor(0.9046)\n",
      "\n",
      "Epoch 442/999:\n",
      "train loss  tensor(0.2791, dtype=torch.float64)\n",
      "train acc   tensor(0.9046)\n",
      "\n",
      "Epoch 443/999:\n",
      "train loss  tensor(0.2788, dtype=torch.float64)\n",
      "train acc   tensor(0.9032)\n",
      "\n",
      "Epoch 444/999:\n",
      "train loss  tensor(0.2789, dtype=torch.float64)\n",
      "train acc   tensor(0.9032)\n",
      "\n",
      "Epoch 445/999:\n",
      "train loss  tensor(0.2791, dtype=torch.float64)\n",
      "train acc   tensor(0.9040)\n",
      "\n",
      "Epoch 446/999:\n",
      "train loss  tensor(0.2783, dtype=torch.float64)\n",
      "train acc   tensor(0.9008)\n",
      "\n",
      "Epoch 447/999:\n",
      "train loss  tensor(0.2787, dtype=torch.float64)\n",
      "train acc   tensor(0.8999)\n",
      "\n",
      "Epoch 448/999:\n",
      "train loss  tensor(0.2785, dtype=torch.float64)\n",
      "train acc   tensor(0.9023)\n",
      "\n",
      "Epoch 449/999:\n",
      "train loss  tensor(0.2783, dtype=torch.float64)\n",
      "train acc   tensor(0.8996)\n",
      "\n",
      "Epoch 450/999:\n",
      "train loss  tensor(0.2779, dtype=torch.float64)\n",
      "train acc   tensor(0.8994)\n",
      "\n",
      "Epoch 451/999:\n",
      "train loss  tensor(0.2769, dtype=torch.float64)\n",
      "train acc   tensor(0.8994)\n",
      "\n",
      "Epoch 452/999:\n",
      "train loss  tensor(0.2771, dtype=torch.float64)\n",
      "train acc   tensor(0.8994)\n",
      "\n",
      "Epoch 453/999:\n",
      "train loss  tensor(0.2772, dtype=torch.float64)\n",
      "train acc   tensor(0.8996)\n",
      "\n",
      "Epoch 454/999:\n",
      "train loss  tensor(0.2773, dtype=torch.float64)\n",
      "train acc   tensor(0.8991)\n",
      "\n",
      "Epoch 455/999:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss  tensor(0.2778, dtype=torch.float64)\n",
      "train acc   tensor(0.8967)\n",
      "\n",
      "Epoch 456/999:\n",
      "train loss  tensor(0.2780, dtype=torch.float64)\n",
      "train acc   tensor(0.8999)\n",
      "\n",
      "Epoch 457/999:\n",
      "train loss  tensor(0.2780, dtype=torch.float64)\n",
      "train acc   tensor(0.9011)\n",
      "\n",
      "Epoch 458/999:\n",
      "train loss  tensor(0.2777, dtype=torch.float64)\n",
      "train acc   tensor(0.9014)\n",
      "\n",
      "Epoch 459/999:\n",
      "train loss  tensor(0.2776, dtype=torch.float64)\n",
      "train acc   tensor(0.8996)\n",
      "\n",
      "Epoch 460/999:\n",
      "train loss  tensor(0.2779, dtype=torch.float64)\n",
      "train acc   tensor(0.8970)\n",
      "\n",
      "Epoch 461/999:\n",
      "train loss  tensor(0.2780, dtype=torch.float64)\n",
      "train acc   tensor(0.8988)\n",
      "\n",
      "Epoch 462/999:\n",
      "train loss  tensor(0.2785, dtype=torch.float64)\n",
      "train acc   tensor(0.8991)\n",
      "\n",
      "Epoch 463/999:\n",
      "train loss  tensor(0.2792, dtype=torch.float64)\n",
      "train acc   tensor(0.8964)\n",
      "\n",
      "Epoch 464/999:\n",
      "train loss  tensor(0.2790, dtype=torch.float64)\n",
      "train acc   tensor(0.8970)\n",
      "\n",
      "Epoch 465/999:\n",
      "train loss  tensor(0.2787, dtype=torch.float64)\n",
      "train acc   tensor(0.8970)\n",
      "\n",
      "Epoch 466/999:\n",
      "train loss  tensor(0.2788, dtype=torch.float64)\n",
      "train acc   tensor(0.8970)\n",
      "\n",
      "Epoch 467/999:\n",
      "train loss  tensor(0.2790, dtype=torch.float64)\n",
      "train acc   tensor(0.8973)\n",
      "\n",
      "Epoch 468/999:\n",
      "train loss  tensor(0.2786, dtype=torch.float64)\n",
      "train acc   tensor(0.8991)\n",
      "\n",
      "Epoch 469/999:\n",
      "train loss  tensor(0.2783, dtype=torch.float64)\n",
      "train acc   tensor(0.8994)\n",
      "\n",
      "Epoch 470/999:\n",
      "train loss  tensor(0.2775, dtype=torch.float64)\n",
      "train acc   tensor(0.8988)\n",
      "\n",
      "Epoch 471/999:\n",
      "train loss  tensor(0.2776, dtype=torch.float64)\n",
      "train acc   tensor(0.8991)\n",
      "\n",
      "Epoch 472/999:\n",
      "train loss  tensor(0.2775, dtype=torch.float64)\n",
      "train acc   tensor(0.8988)\n",
      "\n",
      "Epoch 473/999:\n",
      "train loss  tensor(0.2775, dtype=torch.float64)\n",
      "train acc   tensor(0.8979)\n",
      "\n",
      "Epoch 474/999:\n",
      "train loss  tensor(0.2776, dtype=torch.float64)\n",
      "train acc   tensor(0.9005)\n",
      "\n",
      "Epoch 475/999:\n",
      "train loss  tensor(0.2779, dtype=torch.float64)\n",
      "train acc   tensor(0.9011)\n",
      "\n",
      "Epoch 476/999:\n",
      "train loss  tensor(0.2778, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 477/999:\n",
      "train loss  tensor(0.2782, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 478/999:\n",
      "train loss  tensor(0.2789, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 479/999:\n",
      "train loss  tensor(0.2795, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 480/999:\n",
      "train loss  tensor(0.2787, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 481/999:\n",
      "train loss  tensor(0.2782, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 482/999:\n",
      "train loss  tensor(0.2781, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 483/999:\n",
      "train loss  tensor(0.2780, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 484/999:\n",
      "train loss  tensor(0.2786, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 485/999:\n",
      "train loss  tensor(0.2788, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 486/999:\n",
      "train loss  tensor(0.2787, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 487/999:\n",
      "train loss  tensor(0.2783, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 488/999:\n",
      "train loss  tensor(0.2786, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 489/999:\n",
      "train loss  tensor(0.2787, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 490/999:\n",
      "train loss  tensor(0.2786, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 491/999:\n",
      "train loss  tensor(0.2789, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 492/999:\n",
      "train loss  tensor(0.2792, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 493/999:\n",
      "train loss  tensor(0.2792, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 494/999:\n",
      "train loss  tensor(0.2784, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 495/999:\n",
      "train loss  tensor(0.2785, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 496/999:\n",
      "train loss  tensor(0.2783, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 497/999:\n",
      "train loss  tensor(0.2779, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 498/999:\n",
      "train loss  tensor(0.2779, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 499/999:\n",
      "train loss  tensor(0.2777, dtype=torch.float64)\n",
      "train acc   tensor(0.8929)\n",
      "\n",
      "Epoch 500/999:\n",
      "train loss  tensor(0.2779, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 501/999:\n",
      "train loss  tensor(0.2777, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 502/999:\n",
      "train loss  tensor(0.2775, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 503/999:\n",
      "train loss  tensor(0.2776, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 504/999:\n",
      "train loss  tensor(0.2774, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 505/999:\n",
      "train loss  tensor(0.2772, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 506/999:\n",
      "train loss  tensor(0.2772, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 507/999:\n",
      "train loss  tensor(0.2767, dtype=torch.float64)\n",
      "train acc   tensor(0.8888)\n",
      "\n",
      "Epoch 508/999:\n",
      "train loss  tensor(0.2765, dtype=torch.float64)\n",
      "train acc   tensor(0.8888)\n",
      "\n",
      "Epoch 509/999:\n",
      "train loss  tensor(0.2765, dtype=torch.float64)\n",
      "train acc   tensor(0.8888)\n",
      "\n",
      "Epoch 510/999:\n",
      "train loss  tensor(0.2768, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 511/999:\n",
      "train loss  tensor(0.2766, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 512/999:\n",
      "train loss  tensor(0.2762, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 513/999:\n",
      "train loss  tensor(0.2760, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 514/999:\n",
      "train loss  tensor(0.2757, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 515/999:\n",
      "train loss  tensor(0.2756, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 516/999:\n",
      "train loss  tensor(0.2753, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 517/999:\n",
      "train loss  tensor(0.2750, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 518/999:\n",
      "train loss  tensor(0.2752, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 519/999:\n",
      "train loss  tensor(0.2757, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 520/999:\n",
      "train loss  tensor(0.2775, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 521/999:\n",
      "train loss  tensor(0.2774, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 522/999:\n",
      "train loss  tensor(0.2769, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 523/999:\n",
      "train loss  tensor(0.2764, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 524/999:\n",
      "train loss  tensor(0.2758, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 525/999:\n",
      "train loss  tensor(0.2745, dtype=torch.float64)\n",
      "train acc   tensor(0.9014)\n",
      "\n",
      "Epoch 526/999:\n",
      "train loss  tensor(0.2742, dtype=torch.float64)\n",
      "train acc   tensor(0.9032)\n",
      "\n",
      "Epoch 527/999:\n",
      "train loss  tensor(0.2744, dtype=torch.float64)\n",
      "train acc   tensor(0.9014)\n",
      "\n",
      "Epoch 528/999:\n",
      "train loss  tensor(0.2751, dtype=torch.float64)\n",
      "train acc   tensor(0.9020)\n",
      "\n",
      "Epoch 529/999:\n",
      "train loss  tensor(0.2748, dtype=torch.float64)\n",
      "train acc   tensor(0.9020)\n",
      "\n",
      "Epoch 530/999:\n",
      "train loss  tensor(0.2747, dtype=torch.float64)\n",
      "train acc   tensor(0.8996)\n",
      "\n",
      "Epoch 531/999:\n",
      "train loss  tensor(0.2745, dtype=torch.float64)\n",
      "train acc   tensor(0.9026)\n",
      "\n",
      "Epoch 532/999:\n",
      "train loss  tensor(0.2745, dtype=torch.float64)\n",
      "train acc   tensor(0.9029)\n",
      "\n",
      "Epoch 533/999:\n",
      "train loss  tensor(0.2745, dtype=torch.float64)\n",
      "train acc   tensor(0.8988)\n",
      "\n",
      "Epoch 534/999:\n",
      "train loss  tensor(0.2757, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 535/999:\n",
      "train loss  tensor(0.2752, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 536/999:\n",
      "train loss  tensor(0.2749, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 537/999:\n",
      "train loss  tensor(0.2751, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 538/999:\n",
      "train loss  tensor(0.2751, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 539/999:\n",
      "train loss  tensor(0.2747, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 540/999:\n",
      "train loss  tensor(0.2750, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 541/999:\n",
      "train loss  tensor(0.2751, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 542/999:\n",
      "train loss  tensor(0.2755, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 543/999:\n",
      "train loss  tensor(0.2753, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 544/999:\n",
      "train loss  tensor(0.2745, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 545/999:\n",
      "train loss  tensor(0.2749, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 546/999:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss  tensor(0.2748, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 547/999:\n",
      "train loss  tensor(0.2747, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 548/999:\n",
      "train loss  tensor(0.2740, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 549/999:\n",
      "train loss  tensor(0.2739, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 550/999:\n",
      "train loss  tensor(0.2734, dtype=torch.float64)\n",
      "train acc   tensor(0.8882)\n",
      "\n",
      "Epoch 551/999:\n",
      "train loss  tensor(0.2734, dtype=torch.float64)\n",
      "train acc   tensor(0.8882)\n",
      "\n",
      "Epoch 552/999:\n",
      "train loss  tensor(0.2735, dtype=torch.float64)\n",
      "train acc   tensor(0.8991)\n",
      "\n",
      "Epoch 553/999:\n",
      "train loss  tensor(0.2733, dtype=torch.float64)\n",
      "train acc   tensor(0.8982)\n",
      "\n",
      "Epoch 554/999:\n",
      "train loss  tensor(0.2734, dtype=torch.float64)\n",
      "train acc   tensor(0.9008)\n",
      "\n",
      "Epoch 555/999:\n",
      "train loss  tensor(0.2728, dtype=torch.float64)\n",
      "train acc   tensor(0.9017)\n",
      "\n",
      "Epoch 556/999:\n",
      "train loss  tensor(0.2726, dtype=torch.float64)\n",
      "train acc   tensor(0.9020)\n",
      "\n",
      "Epoch 557/999:\n",
      "train loss  tensor(0.2722, dtype=torch.float64)\n",
      "train acc   tensor(0.9002)\n",
      "\n",
      "Epoch 558/999:\n",
      "train loss  tensor(0.2722, dtype=torch.float64)\n",
      "train acc   tensor(0.9011)\n",
      "\n",
      "Epoch 559/999:\n",
      "train loss  tensor(0.2730, dtype=torch.float64)\n",
      "train acc   tensor(0.8982)\n",
      "\n",
      "Epoch 560/999:\n",
      "train loss  tensor(0.2736, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 561/999:\n",
      "train loss  tensor(0.2738, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 562/999:\n",
      "train loss  tensor(0.2735, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 563/999:\n",
      "train loss  tensor(0.2738, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 564/999:\n",
      "train loss  tensor(0.2753, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 565/999:\n",
      "train loss  tensor(0.2752, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 566/999:\n",
      "train loss  tensor(0.2751, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 567/999:\n",
      "train loss  tensor(0.2758, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 568/999:\n",
      "train loss  tensor(0.2760, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 569/999:\n",
      "train loss  tensor(0.2755, dtype=torch.float64)\n",
      "train acc   tensor(0.8888)\n",
      "\n",
      "Epoch 570/999:\n",
      "train loss  tensor(0.2758, dtype=torch.float64)\n",
      "train acc   tensor(0.8888)\n",
      "\n",
      "Epoch 571/999:\n",
      "train loss  tensor(0.2744, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 572/999:\n",
      "train loss  tensor(0.2743, dtype=torch.float64)\n",
      "train acc   tensor(0.8932)\n",
      "\n",
      "Epoch 573/999:\n",
      "train loss  tensor(0.2740, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 574/999:\n",
      "train loss  tensor(0.2738, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 575/999:\n",
      "train loss  tensor(0.2733, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 576/999:\n",
      "train loss  tensor(0.2733, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 577/999:\n",
      "train loss  tensor(0.2738, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 578/999:\n",
      "train loss  tensor(0.2737, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 579/999:\n",
      "train loss  tensor(0.2741, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 580/999:\n",
      "train loss  tensor(0.2739, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 581/999:\n",
      "train loss  tensor(0.2746, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 582/999:\n",
      "train loss  tensor(0.2747, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 583/999:\n",
      "train loss  tensor(0.2742, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 584/999:\n",
      "train loss  tensor(0.2740, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 585/999:\n",
      "train loss  tensor(0.2736, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 586/999:\n",
      "train loss  tensor(0.2731, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 587/999:\n",
      "train loss  tensor(0.2730, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 588/999:\n",
      "train loss  tensor(0.2735, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 589/999:\n",
      "train loss  tensor(0.2732, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 590/999:\n",
      "train loss  tensor(0.2736, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 591/999:\n",
      "train loss  tensor(0.2741, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 592/999:\n",
      "train loss  tensor(0.2736, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 593/999:\n",
      "train loss  tensor(0.2734, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 594/999:\n",
      "train loss  tensor(0.2737, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 595/999:\n",
      "train loss  tensor(0.2738, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 596/999:\n",
      "train loss  tensor(0.2744, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 597/999:\n",
      "train loss  tensor(0.2740, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 598/999:\n",
      "train loss  tensor(0.2748, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 599/999:\n",
      "train loss  tensor(0.2749, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 600/999:\n",
      "train loss  tensor(0.2735, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 601/999:\n",
      "train loss  tensor(0.2731, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 602/999:\n",
      "train loss  tensor(0.2730, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 603/999:\n",
      "train loss  tensor(0.2726, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 604/999:\n",
      "train loss  tensor(0.2726, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 605/999:\n",
      "train loss  tensor(0.2722, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 606/999:\n",
      "train loss  tensor(0.2721, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 607/999:\n",
      "train loss  tensor(0.2721, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 608/999:\n",
      "train loss  tensor(0.2725, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 609/999:\n",
      "train loss  tensor(0.2720, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 610/999:\n",
      "train loss  tensor(0.2725, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 611/999:\n",
      "train loss  tensor(0.2724, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 612/999:\n",
      "train loss  tensor(0.2729, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 613/999:\n",
      "train loss  tensor(0.2724, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 614/999:\n",
      "train loss  tensor(0.2721, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 615/999:\n",
      "train loss  tensor(0.2719, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 616/999:\n",
      "train loss  tensor(0.2718, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 617/999:\n",
      "train loss  tensor(0.2716, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 618/999:\n",
      "train loss  tensor(0.2713, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 619/999:\n",
      "train loss  tensor(0.2716, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 620/999:\n",
      "train loss  tensor(0.2714, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 621/999:\n",
      "train loss  tensor(0.2720, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 622/999:\n",
      "train loss  tensor(0.2720, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 623/999:\n",
      "train loss  tensor(0.2723, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 624/999:\n",
      "train loss  tensor(0.2726, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 625/999:\n",
      "train loss  tensor(0.2715, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 626/999:\n",
      "train loss  tensor(0.2717, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 627/999:\n",
      "train loss  tensor(0.2717, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 628/999:\n",
      "train loss  tensor(0.2719, dtype=torch.float64)\n",
      "train acc   tensor(0.8882)\n",
      "\n",
      "Epoch 629/999:\n",
      "train loss  tensor(0.2720, dtype=torch.float64)\n",
      "train acc   tensor(0.8876)\n",
      "\n",
      "Epoch 630/999:\n",
      "train loss  tensor(0.2716, dtype=torch.float64)\n",
      "train acc   tensor(0.8882)\n",
      "\n",
      "Epoch 631/999:\n",
      "train loss  tensor(0.2711, dtype=torch.float64)\n",
      "train acc   tensor(0.8882)\n",
      "\n",
      "Epoch 632/999:\n",
      "train loss  tensor(0.2709, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 633/999:\n",
      "train loss  tensor(0.2706, dtype=torch.float64)\n",
      "train acc   tensor(0.8888)\n",
      "\n",
      "Epoch 634/999:\n",
      "train loss  tensor(0.2705, dtype=torch.float64)\n",
      "train acc   tensor(0.8888)\n",
      "\n",
      "Epoch 635/999:\n",
      "train loss  tensor(0.2706, dtype=torch.float64)\n",
      "train acc   tensor(0.8888)\n",
      "\n",
      "Epoch 636/999:\n",
      "train loss  tensor(0.2705, dtype=torch.float64)\n",
      "train acc   tensor(0.8882)\n",
      "\n",
      "Epoch 637/999:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss  tensor(0.2703, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 638/999:\n",
      "train loss  tensor(0.2701, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 639/999:\n",
      "train loss  tensor(0.2699, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 640/999:\n",
      "train loss  tensor(0.2704, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 641/999:\n",
      "train loss  tensor(0.2704, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 642/999:\n",
      "train loss  tensor(0.2706, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 643/999:\n",
      "train loss  tensor(0.2699, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 644/999:\n",
      "train loss  tensor(0.2700, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 645/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 646/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 647/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 648/999:\n",
      "train loss  tensor(0.2698, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 649/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 650/999:\n",
      "train loss  tensor(0.2697, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 651/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 652/999:\n",
      "train loss  tensor(0.2695, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 653/999:\n",
      "train loss  tensor(0.2694, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 654/999:\n",
      "train loss  tensor(0.2697, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 655/999:\n",
      "train loss  tensor(0.2695, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 656/999:\n",
      "train loss  tensor(0.2695, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 657/999:\n",
      "train loss  tensor(0.2694, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 658/999:\n",
      "train loss  tensor(0.2697, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 659/999:\n",
      "train loss  tensor(0.2691, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 660/999:\n",
      "train loss  tensor(0.2694, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 661/999:\n",
      "train loss  tensor(0.2694, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 662/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 663/999:\n",
      "train loss  tensor(0.2695, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 664/999:\n",
      "train loss  tensor(0.2694, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 665/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 666/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 667/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 668/999:\n",
      "train loss  tensor(0.2695, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 669/999:\n",
      "train loss  tensor(0.2698, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 670/999:\n",
      "train loss  tensor(0.2698, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 671/999:\n",
      "train loss  tensor(0.2695, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 672/999:\n",
      "train loss  tensor(0.2693, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 673/999:\n",
      "train loss  tensor(0.2691, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 674/999:\n",
      "train loss  tensor(0.2693, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 675/999:\n",
      "train loss  tensor(0.2697, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 676/999:\n",
      "train loss  tensor(0.2695, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 677/999:\n",
      "train loss  tensor(0.2694, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 678/999:\n",
      "train loss  tensor(0.2692, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 679/999:\n",
      "train loss  tensor(0.2690, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 680/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 681/999:\n",
      "train loss  tensor(0.2694, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 682/999:\n",
      "train loss  tensor(0.2695, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 683/999:\n",
      "train loss  tensor(0.2695, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 684/999:\n",
      "train loss  tensor(0.2691, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 685/999:\n",
      "train loss  tensor(0.2693, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 686/999:\n",
      "train loss  tensor(0.2692, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 687/999:\n",
      "train loss  tensor(0.2687, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 688/999:\n",
      "train loss  tensor(0.2684, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 689/999:\n",
      "train loss  tensor(0.2683, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 690/999:\n",
      "train loss  tensor(0.2683, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 691/999:\n",
      "train loss  tensor(0.2680, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 692/999:\n",
      "train loss  tensor(0.2681, dtype=torch.float64)\n",
      "train acc   tensor(0.8929)\n",
      "\n",
      "Epoch 693/999:\n",
      "train loss  tensor(0.2682, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 694/999:\n",
      "train loss  tensor(0.2678, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 695/999:\n",
      "train loss  tensor(0.2681, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 696/999:\n",
      "train loss  tensor(0.2683, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 697/999:\n",
      "train loss  tensor(0.2677, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 698/999:\n",
      "train loss  tensor(0.2679, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 699/999:\n",
      "train loss  tensor(0.2683, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 700/999:\n",
      "train loss  tensor(0.2681, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 701/999:\n",
      "train loss  tensor(0.2682, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 702/999:\n",
      "train loss  tensor(0.2683, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 703/999:\n",
      "train loss  tensor(0.2683, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 704/999:\n",
      "train loss  tensor(0.2694, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 705/999:\n",
      "train loss  tensor(0.2694, dtype=torch.float64)\n",
      "train acc   tensor(0.8870)\n",
      "\n",
      "Epoch 706/999:\n",
      "train loss  tensor(0.2702, dtype=torch.float64)\n",
      "train acc   tensor(0.8870)\n",
      "\n",
      "Epoch 707/999:\n",
      "train loss  tensor(0.2700, dtype=torch.float64)\n",
      "train acc   tensor(0.8867)\n",
      "\n",
      "Epoch 708/999:\n",
      "train loss  tensor(0.2702, dtype=torch.float64)\n",
      "train acc   tensor(0.8873)\n",
      "\n",
      "Epoch 709/999:\n",
      "train loss  tensor(0.2701, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 710/999:\n",
      "train loss  tensor(0.2698, dtype=torch.float64)\n",
      "train acc   tensor(0.8888)\n",
      "\n",
      "Epoch 711/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 712/999:\n",
      "train loss  tensor(0.2697, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 713/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 714/999:\n",
      "train loss  tensor(0.2695, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 715/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 716/999:\n",
      "train loss  tensor(0.2695, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 717/999:\n",
      "train loss  tensor(0.2695, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 718/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 719/999:\n",
      "train loss  tensor(0.2690, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 720/999:\n",
      "train loss  tensor(0.2688, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 721/999:\n",
      "train loss  tensor(0.2685, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 722/999:\n",
      "train loss  tensor(0.2706, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 723/999:\n",
      "train loss  tensor(0.2703, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 724/999:\n",
      "train loss  tensor(0.2701, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 725/999:\n",
      "train loss  tensor(0.2695, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 726/999:\n",
      "train loss  tensor(0.2697, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 727/999:\n",
      "train loss  tensor(0.2694, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 728/999:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss  tensor(0.2692, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 729/999:\n",
      "train loss  tensor(0.2689, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 730/999:\n",
      "train loss  tensor(0.2685, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 731/999:\n",
      "train loss  tensor(0.2681, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 732/999:\n",
      "train loss  tensor(0.2683, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 733/999:\n",
      "train loss  tensor(0.2679, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 734/999:\n",
      "train loss  tensor(0.2671, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 735/999:\n",
      "train loss  tensor(0.2691, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 736/999:\n",
      "train loss  tensor(0.2684, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 737/999:\n",
      "train loss  tensor(0.2679, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 738/999:\n",
      "train loss  tensor(0.2682, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 739/999:\n",
      "train loss  tensor(0.2681, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 740/999:\n",
      "train loss  tensor(0.2684, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 741/999:\n",
      "train loss  tensor(0.2681, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 742/999:\n",
      "train loss  tensor(0.2682, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 743/999:\n",
      "train loss  tensor(0.2681, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 744/999:\n",
      "train loss  tensor(0.2680, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 745/999:\n",
      "train loss  tensor(0.2677, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 746/999:\n",
      "train loss  tensor(0.2673, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 747/999:\n",
      "train loss  tensor(0.2678, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 748/999:\n",
      "train loss  tensor(0.2670, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 749/999:\n",
      "train loss  tensor(0.2666, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 750/999:\n",
      "train loss  tensor(0.2663, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 751/999:\n",
      "train loss  tensor(0.2665, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 752/999:\n",
      "train loss  tensor(0.2666, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 753/999:\n",
      "train loss  tensor(0.2661, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 754/999:\n",
      "train loss  tensor(0.2657, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 755/999:\n",
      "train loss  tensor(0.2667, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 756/999:\n",
      "train loss  tensor(0.2661, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 757/999:\n",
      "train loss  tensor(0.2661, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 758/999:\n",
      "train loss  tensor(0.2676, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 759/999:\n",
      "train loss  tensor(0.2679, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 760/999:\n",
      "train loss  tensor(0.2685, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 761/999:\n",
      "train loss  tensor(0.2683, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 762/999:\n",
      "train loss  tensor(0.2686, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 763/999:\n",
      "train loss  tensor(0.2683, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 764/999:\n",
      "train loss  tensor(0.2682, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 765/999:\n",
      "train loss  tensor(0.2689, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 766/999:\n",
      "train loss  tensor(0.2690, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 767/999:\n",
      "train loss  tensor(0.2692, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 768/999:\n",
      "train loss  tensor(0.2693, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 769/999:\n",
      "train loss  tensor(0.2708, dtype=torch.float64)\n",
      "train acc   tensor(0.8882)\n",
      "\n",
      "Epoch 770/999:\n",
      "train loss  tensor(0.2705, dtype=torch.float64)\n",
      "train acc   tensor(0.8888)\n",
      "\n",
      "Epoch 771/999:\n",
      "train loss  tensor(0.2701, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 772/999:\n",
      "train loss  tensor(0.2690, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 773/999:\n",
      "train loss  tensor(0.2689, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 774/999:\n",
      "train loss  tensor(0.2689, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 775/999:\n",
      "train loss  tensor(0.2692, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 776/999:\n",
      "train loss  tensor(0.2689, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 777/999:\n",
      "train loss  tensor(0.2682, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 778/999:\n",
      "train loss  tensor(0.2693, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 779/999:\n",
      "train loss  tensor(0.2690, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 780/999:\n",
      "train loss  tensor(0.2686, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 781/999:\n",
      "train loss  tensor(0.2674, dtype=torch.float64)\n",
      "train acc   tensor(0.9014)\n",
      "\n",
      "Epoch 782/999:\n",
      "train loss  tensor(0.2674, dtype=torch.float64)\n",
      "train acc   tensor(0.9017)\n",
      "\n",
      "Epoch 783/999:\n",
      "train loss  tensor(0.2676, dtype=torch.float64)\n",
      "train acc   tensor(0.8991)\n",
      "\n",
      "Epoch 784/999:\n",
      "train loss  tensor(0.2678, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 785/999:\n",
      "train loss  tensor(0.2678, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 786/999:\n",
      "train loss  tensor(0.2678, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 787/999:\n",
      "train loss  tensor(0.2673, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 788/999:\n",
      "train loss  tensor(0.2672, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 789/999:\n",
      "train loss  tensor(0.2673, dtype=torch.float64)\n",
      "train acc   tensor(0.8864)\n",
      "\n",
      "Epoch 790/999:\n",
      "train loss  tensor(0.2674, dtype=torch.float64)\n",
      "train acc   tensor(0.8867)\n",
      "\n",
      "Epoch 791/999:\n",
      "train loss  tensor(0.2671, dtype=torch.float64)\n",
      "train acc   tensor(0.8870)\n",
      "\n",
      "Epoch 792/999:\n",
      "train loss  tensor(0.2674, dtype=torch.float64)\n",
      "train acc   tensor(0.8879)\n",
      "\n",
      "Epoch 793/999:\n",
      "train loss  tensor(0.2683, dtype=torch.float64)\n",
      "train acc   tensor(0.8873)\n",
      "\n",
      "Epoch 794/999:\n",
      "train loss  tensor(0.2686, dtype=torch.float64)\n",
      "train acc   tensor(0.8876)\n",
      "\n",
      "Epoch 795/999:\n",
      "train loss  tensor(0.2682, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 796/999:\n",
      "train loss  tensor(0.2678, dtype=torch.float64)\n",
      "train acc   tensor(0.8888)\n",
      "\n",
      "Epoch 797/999:\n",
      "train loss  tensor(0.2673, dtype=torch.float64)\n",
      "train acc   tensor(0.8888)\n",
      "\n",
      "Epoch 798/999:\n",
      "train loss  tensor(0.2674, dtype=torch.float64)\n",
      "train acc   tensor(0.8885)\n",
      "\n",
      "Epoch 799/999:\n",
      "train loss  tensor(0.2671, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 800/999:\n",
      "train loss  tensor(0.2670, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 801/999:\n",
      "train loss  tensor(0.2667, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 802/999:\n",
      "train loss  tensor(0.2665, dtype=torch.float64)\n",
      "train acc   tensor(0.8932)\n",
      "\n",
      "Epoch 803/999:\n",
      "train loss  tensor(0.2666, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 804/999:\n",
      "train loss  tensor(0.2665, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 805/999:\n",
      "train loss  tensor(0.2676, dtype=torch.float64)\n",
      "train acc   tensor(0.8929)\n",
      "\n",
      "Epoch 806/999:\n",
      "train loss  tensor(0.2674, dtype=torch.float64)\n",
      "train acc   tensor(0.8935)\n",
      "\n",
      "Epoch 807/999:\n",
      "train loss  tensor(0.2670, dtype=torch.float64)\n",
      "train acc   tensor(0.8938)\n",
      "\n",
      "Epoch 808/999:\n",
      "train loss  tensor(0.2670, dtype=torch.float64)\n",
      "train acc   tensor(0.8938)\n",
      "\n",
      "Epoch 809/999:\n",
      "train loss  tensor(0.2670, dtype=torch.float64)\n",
      "train acc   tensor(0.8938)\n",
      "\n",
      "Epoch 810/999:\n",
      "train loss  tensor(0.2668, dtype=torch.float64)\n",
      "train acc   tensor(0.8935)\n",
      "\n",
      "Epoch 811/999:\n",
      "train loss  tensor(0.2665, dtype=torch.float64)\n",
      "train acc   tensor(0.8938)\n",
      "\n",
      "Epoch 812/999:\n",
      "train loss  tensor(0.2676, dtype=torch.float64)\n",
      "train acc   tensor(0.8941)\n",
      "\n",
      "Epoch 813/999:\n",
      "train loss  tensor(0.2677, dtype=torch.float64)\n",
      "train acc   tensor(0.8938)\n",
      "\n",
      "Epoch 814/999:\n",
      "train loss  tensor(0.2681, dtype=torch.float64)\n",
      "train acc   tensor(0.8935)\n",
      "\n",
      "Epoch 815/999:\n",
      "train loss  tensor(0.2691, dtype=torch.float64)\n",
      "train acc   tensor(0.8935)\n",
      "\n",
      "Epoch 816/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8935)\n",
      "\n",
      "Epoch 817/999:\n",
      "train loss  tensor(0.2702, dtype=torch.float64)\n",
      "train acc   tensor(0.8941)\n",
      "\n",
      "Epoch 818/999:\n",
      "train loss  tensor(0.2705, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 819/999:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss  tensor(0.2718, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 820/999:\n",
      "train loss  tensor(0.2710, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 821/999:\n",
      "train loss  tensor(0.2705, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 822/999:\n",
      "train loss  tensor(0.2706, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 823/999:\n",
      "train loss  tensor(0.2716, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 824/999:\n",
      "train loss  tensor(0.2712, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 825/999:\n",
      "train loss  tensor(0.2705, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 826/999:\n",
      "train loss  tensor(0.2703, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 827/999:\n",
      "train loss  tensor(0.2701, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 828/999:\n",
      "train loss  tensor(0.2700, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 829/999:\n",
      "train loss  tensor(0.2699, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 830/999:\n",
      "train loss  tensor(0.2697, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 831/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 832/999:\n",
      "train loss  tensor(0.2706, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 833/999:\n",
      "train loss  tensor(0.2701, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 834/999:\n",
      "train loss  tensor(0.2702, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 835/999:\n",
      "train loss  tensor(0.2691, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 836/999:\n",
      "train loss  tensor(0.2700, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 837/999:\n",
      "train loss  tensor(0.2690, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 838/999:\n",
      "train loss  tensor(0.2685, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 839/999:\n",
      "train loss  tensor(0.2687, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 840/999:\n",
      "train loss  tensor(0.2683, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 841/999:\n",
      "train loss  tensor(0.2690, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 842/999:\n",
      "train loss  tensor(0.2701, dtype=torch.float64)\n",
      "train acc   tensor(0.8879)\n",
      "\n",
      "Epoch 843/999:\n",
      "train loss  tensor(0.2704, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 844/999:\n",
      "train loss  tensor(0.2705, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 845/999:\n",
      "train loss  tensor(0.2705, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 846/999:\n",
      "train loss  tensor(0.2714, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 847/999:\n",
      "train loss  tensor(0.2707, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 848/999:\n",
      "train loss  tensor(0.2697, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 849/999:\n",
      "train loss  tensor(0.2703, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 850/999:\n",
      "train loss  tensor(0.2698, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 851/999:\n",
      "train loss  tensor(0.2699, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 852/999:\n",
      "train loss  tensor(0.2698, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 853/999:\n",
      "train loss  tensor(0.2693, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 854/999:\n",
      "train loss  tensor(0.2687, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 855/999:\n",
      "train loss  tensor(0.2695, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 856/999:\n",
      "train loss  tensor(0.2689, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 857/999:\n",
      "train loss  tensor(0.2693, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 858/999:\n",
      "train loss  tensor(0.2694, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 859/999:\n",
      "train loss  tensor(0.2690, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 860/999:\n",
      "train loss  tensor(0.2691, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 861/999:\n",
      "train loss  tensor(0.2692, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 862/999:\n",
      "train loss  tensor(0.2703, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 863/999:\n",
      "train loss  tensor(0.2703, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 864/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 865/999:\n",
      "train loss  tensor(0.2685, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 866/999:\n",
      "train loss  tensor(0.2685, dtype=torch.float64)\n",
      "train acc   tensor(0.8929)\n",
      "\n",
      "Epoch 867/999:\n",
      "train loss  tensor(0.2684, dtype=torch.float64)\n",
      "train acc   tensor(0.8938)\n",
      "\n",
      "Epoch 868/999:\n",
      "train loss  tensor(0.2677, dtype=torch.float64)\n",
      "train acc   tensor(0.8938)\n",
      "\n",
      "Epoch 869/999:\n",
      "train loss  tensor(0.2688, dtype=torch.float64)\n",
      "train acc   tensor(0.8929)\n",
      "\n",
      "Epoch 870/999:\n",
      "train loss  tensor(0.2685, dtype=torch.float64)\n",
      "train acc   tensor(0.8935)\n",
      "\n",
      "Epoch 871/999:\n",
      "train loss  tensor(0.2682, dtype=torch.float64)\n",
      "train acc   tensor(0.8935)\n",
      "\n",
      "Epoch 872/999:\n",
      "train loss  tensor(0.2679, dtype=torch.float64)\n",
      "train acc   tensor(0.8935)\n",
      "\n",
      "Epoch 873/999:\n",
      "train loss  tensor(0.2683, dtype=torch.float64)\n",
      "train acc   tensor(0.8929)\n",
      "\n",
      "Epoch 874/999:\n",
      "train loss  tensor(0.2681, dtype=torch.float64)\n",
      "train acc   tensor(0.8929)\n",
      "\n",
      "Epoch 875/999:\n",
      "train loss  tensor(0.2676, dtype=torch.float64)\n",
      "train acc   tensor(0.8929)\n",
      "\n",
      "Epoch 876/999:\n",
      "train loss  tensor(0.2670, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 877/999:\n",
      "train loss  tensor(0.2670, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 878/999:\n",
      "train loss  tensor(0.2679, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 879/999:\n",
      "train loss  tensor(0.2685, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 880/999:\n",
      "train loss  tensor(0.2684, dtype=torch.float64)\n",
      "train acc   tensor(0.8932)\n",
      "\n",
      "Epoch 881/999:\n",
      "train loss  tensor(0.2701, dtype=torch.float64)\n",
      "train acc   tensor(0.8935)\n",
      "\n",
      "Epoch 882/999:\n",
      "train loss  tensor(0.2703, dtype=torch.float64)\n",
      "train acc   tensor(0.8932)\n",
      "\n",
      "Epoch 883/999:\n",
      "train loss  tensor(0.2682, dtype=torch.float64)\n",
      "train acc   tensor(0.8941)\n",
      "\n",
      "Epoch 884/999:\n",
      "train loss  tensor(0.2698, dtype=torch.float64)\n",
      "train acc   tensor(0.8944)\n",
      "\n",
      "Epoch 885/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8929)\n",
      "\n",
      "Epoch 886/999:\n",
      "train loss  tensor(0.2695, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 887/999:\n",
      "train loss  tensor(0.2697, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 888/999:\n",
      "train loss  tensor(0.2702, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 889/999:\n",
      "train loss  tensor(0.2697, dtype=torch.float64)\n",
      "train acc   tensor(0.8938)\n",
      "\n",
      "Epoch 890/999:\n",
      "train loss  tensor(0.2697, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 891/999:\n",
      "train loss  tensor(0.2698, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 892/999:\n",
      "train loss  tensor(0.2700, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 893/999:\n",
      "train loss  tensor(0.2695, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 894/999:\n",
      "train loss  tensor(0.2692, dtype=torch.float64)\n",
      "train acc   tensor(0.8929)\n",
      "\n",
      "Epoch 895/999:\n",
      "train loss  tensor(0.2688, dtype=torch.float64)\n",
      "train acc   tensor(0.8929)\n",
      "\n",
      "Epoch 896/999:\n",
      "train loss  tensor(0.2689, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 897/999:\n",
      "train loss  tensor(0.2697, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 898/999:\n",
      "train loss  tensor(0.2696, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 899/999:\n",
      "train loss  tensor(0.2688, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 900/999:\n",
      "train loss  tensor(0.2686, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 901/999:\n",
      "train loss  tensor(0.2687, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 902/999:\n",
      "train loss  tensor(0.2682, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 903/999:\n",
      "train loss  tensor(0.2682, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 904/999:\n",
      "train loss  tensor(0.2680, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 905/999:\n",
      "train loss  tensor(0.2679, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 906/999:\n",
      "train loss  tensor(0.2682, dtype=torch.float64)\n",
      "train acc   tensor(0.8929)\n",
      "\n",
      "Epoch 907/999:\n",
      "train loss  tensor(0.2683, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 908/999:\n",
      "train loss  tensor(0.2688, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 909/999:\n",
      "train loss  tensor(0.2690, dtype=torch.float64)\n",
      "train acc   tensor(0.8900)\n",
      "\n",
      "Epoch 910/999:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss  tensor(0.2686, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 911/999:\n",
      "train loss  tensor(0.2684, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 912/999:\n",
      "train loss  tensor(0.2679, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 913/999:\n",
      "train loss  tensor(0.2673, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 914/999:\n",
      "train loss  tensor(0.2671, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 915/999:\n",
      "train loss  tensor(0.2676, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 916/999:\n",
      "train loss  tensor(0.2674, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 917/999:\n",
      "train loss  tensor(0.2671, dtype=torch.float64)\n",
      "train acc   tensor(0.8938)\n",
      "\n",
      "Epoch 918/999:\n",
      "train loss  tensor(0.2669, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 919/999:\n",
      "train loss  tensor(0.2668, dtype=torch.float64)\n",
      "train acc   tensor(0.8914)\n",
      "\n",
      "Epoch 920/999:\n",
      "train loss  tensor(0.2665, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 921/999:\n",
      "train loss  tensor(0.2663, dtype=torch.float64)\n",
      "train acc   tensor(0.8920)\n",
      "\n",
      "Epoch 922/999:\n",
      "train loss  tensor(0.2663, dtype=torch.float64)\n",
      "train acc   tensor(0.8917)\n",
      "\n",
      "Epoch 923/999:\n",
      "train loss  tensor(0.2663, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 924/999:\n",
      "train loss  tensor(0.2658, dtype=torch.float64)\n",
      "train acc   tensor(0.8891)\n",
      "\n",
      "Epoch 925/999:\n",
      "train loss  tensor(0.2662, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 926/999:\n",
      "train loss  tensor(0.2665, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 927/999:\n",
      "train loss  tensor(0.2664, dtype=torch.float64)\n",
      "train acc   tensor(0.8894)\n",
      "\n",
      "Epoch 928/999:\n",
      "train loss  tensor(0.2665, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 929/999:\n",
      "train loss  tensor(0.2660, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 930/999:\n",
      "train loss  tensor(0.2661, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 931/999:\n",
      "train loss  tensor(0.2661, dtype=torch.float64)\n",
      "train acc   tensor(0.8929)\n",
      "\n",
      "Epoch 932/999:\n",
      "train loss  tensor(0.2658, dtype=torch.float64)\n",
      "train acc   tensor(0.8926)\n",
      "\n",
      "Epoch 933/999:\n",
      "train loss  tensor(0.2661, dtype=torch.float64)\n",
      "train acc   tensor(0.8932)\n",
      "\n",
      "Epoch 934/999:\n",
      "train loss  tensor(0.2659, dtype=torch.float64)\n",
      "train acc   tensor(0.8947)\n",
      "\n",
      "Epoch 935/999:\n",
      "train loss  tensor(0.2658, dtype=torch.float64)\n",
      "train acc   tensor(0.8944)\n",
      "\n",
      "Epoch 936/999:\n",
      "train loss  tensor(0.2662, dtype=torch.float64)\n",
      "train acc   tensor(0.8944)\n",
      "\n",
      "Epoch 937/999:\n",
      "train loss  tensor(0.2664, dtype=torch.float64)\n",
      "train acc   tensor(0.8941)\n",
      "\n",
      "Epoch 938/999:\n",
      "train loss  tensor(0.2662, dtype=torch.float64)\n",
      "train acc   tensor(0.8941)\n",
      "\n",
      "Epoch 939/999:\n",
      "train loss  tensor(0.2662, dtype=torch.float64)\n",
      "train acc   tensor(0.8897)\n",
      "\n",
      "Epoch 940/999:\n",
      "train loss  tensor(0.2656, dtype=torch.float64)\n",
      "train acc   tensor(0.8903)\n",
      "\n",
      "Epoch 941/999:\n",
      "train loss  tensor(0.2654, dtype=torch.float64)\n",
      "train acc   tensor(0.8908)\n",
      "\n",
      "Epoch 942/999:\n",
      "train loss  tensor(0.2656, dtype=torch.float64)\n",
      "train acc   tensor(0.8911)\n",
      "\n",
      "Epoch 943/999:\n",
      "train loss  tensor(0.2651, dtype=torch.float64)\n",
      "train acc   tensor(0.8906)\n",
      "\n",
      "Epoch 944/999:\n",
      "train loss  tensor(0.2656, dtype=torch.float64)\n",
      "train acc   tensor(0.8929)\n",
      "\n",
      "Epoch 945/999:\n",
      "train loss  tensor(0.2656, dtype=torch.float64)\n",
      "train acc   tensor(0.8955)\n",
      "\n",
      "Epoch 946/999:\n",
      "train loss  tensor(0.2655, dtype=torch.float64)\n",
      "train acc   tensor(0.8952)\n",
      "\n",
      "Epoch 947/999:\n",
      "train loss  tensor(0.2650, dtype=torch.float64)\n",
      "train acc   tensor(0.8950)\n",
      "\n",
      "Epoch 948/999:\n",
      "train loss  tensor(0.2656, dtype=torch.float64)\n",
      "train acc   tensor(0.8950)\n",
      "\n",
      "Epoch 949/999:\n",
      "train loss  tensor(0.2651, dtype=torch.float64)\n",
      "train acc   tensor(0.8955)\n",
      "\n",
      "Epoch 950/999:\n",
      "train loss  tensor(0.2647, dtype=torch.float64)\n",
      "train acc   tensor(0.8955)\n",
      "\n",
      "Epoch 951/999:\n",
      "train loss  tensor(0.2637, dtype=torch.float64)\n",
      "train acc   tensor(0.8955)\n",
      "\n",
      "Epoch 952/999:\n",
      "train loss  tensor(0.2651, dtype=torch.float64)\n",
      "train acc   tensor(0.8950)\n",
      "\n",
      "Epoch 953/999:\n",
      "train loss  tensor(0.2648, dtype=torch.float64)\n",
      "train acc   tensor(0.8950)\n",
      "\n",
      "Epoch 954/999:\n",
      "train loss  tensor(0.2643, dtype=torch.float64)\n",
      "train acc   tensor(0.8958)\n",
      "\n",
      "Epoch 955/999:\n",
      "train loss  tensor(0.2647, dtype=torch.float64)\n",
      "train acc   tensor(0.8958)\n",
      "\n",
      "Epoch 956/999:\n",
      "train loss  tensor(0.2649, dtype=torch.float64)\n",
      "train acc   tensor(0.8950)\n",
      "\n",
      "Epoch 957/999:\n",
      "train loss  tensor(0.2646, dtype=torch.float64)\n",
      "train acc   tensor(0.8955)\n",
      "\n",
      "Epoch 958/999:\n",
      "train loss  tensor(0.2648, dtype=torch.float64)\n",
      "train acc   tensor(0.8958)\n",
      "\n",
      "Epoch 959/999:\n",
      "train loss  tensor(0.2644, dtype=torch.float64)\n",
      "train acc   tensor(0.8958)\n",
      "\n",
      "Epoch 960/999:\n",
      "train loss  tensor(0.2646, dtype=torch.float64)\n",
      "train acc   tensor(0.8961)\n",
      "\n",
      "Epoch 961/999:\n",
      "train loss  tensor(0.2642, dtype=torch.float64)\n",
      "train acc   tensor(0.8961)\n",
      "\n",
      "Epoch 962/999:\n",
      "train loss  tensor(0.2643, dtype=torch.float64)\n",
      "train acc   tensor(0.8961)\n",
      "\n",
      "Epoch 963/999:\n",
      "train loss  tensor(0.2641, dtype=torch.float64)\n",
      "train acc   tensor(0.8961)\n",
      "\n",
      "Epoch 964/999:\n",
      "train loss  tensor(0.2638, dtype=torch.float64)\n",
      "train acc   tensor(0.8958)\n",
      "\n",
      "Epoch 965/999:\n",
      "train loss  tensor(0.2637, dtype=torch.float64)\n",
      "train acc   tensor(0.8952)\n",
      "\n",
      "Epoch 966/999:\n",
      "train loss  tensor(0.2636, dtype=torch.float64)\n",
      "train acc   tensor(0.8958)\n",
      "\n",
      "Epoch 967/999:\n",
      "train loss  tensor(0.2637, dtype=torch.float64)\n",
      "train acc   tensor(0.8947)\n",
      "\n",
      "Epoch 968/999:\n",
      "train loss  tensor(0.2639, dtype=torch.float64)\n",
      "train acc   tensor(0.8941)\n",
      "\n",
      "Epoch 969/999:\n",
      "train loss  tensor(0.2638, dtype=torch.float64)\n",
      "train acc   tensor(0.8944)\n",
      "\n",
      "Epoch 970/999:\n",
      "train loss  tensor(0.2634, dtype=torch.float64)\n",
      "train acc   tensor(0.8941)\n",
      "\n",
      "Epoch 971/999:\n",
      "train loss  tensor(0.2632, dtype=torch.float64)\n",
      "train acc   tensor(0.8941)\n",
      "\n",
      "Epoch 972/999:\n",
      "train loss  tensor(0.2629, dtype=torch.float64)\n",
      "train acc   tensor(0.8941)\n",
      "\n",
      "Epoch 973/999:\n",
      "train loss  tensor(0.2632, dtype=torch.float64)\n",
      "train acc   tensor(0.8941)\n",
      "\n",
      "Epoch 974/999:\n",
      "train loss  tensor(0.2628, dtype=torch.float64)\n",
      "train acc   tensor(0.8941)\n",
      "\n",
      "Epoch 975/999:\n",
      "train loss  tensor(0.2630, dtype=torch.float64)\n",
      "train acc   tensor(0.8941)\n",
      "\n",
      "Epoch 976/999:\n",
      "train loss  tensor(0.2630, dtype=torch.float64)\n",
      "train acc   tensor(0.8950)\n",
      "\n",
      "Epoch 977/999:\n",
      "train loss  tensor(0.2630, dtype=torch.float64)\n",
      "train acc   tensor(0.8952)\n",
      "\n",
      "Epoch 978/999:\n",
      "train loss  tensor(0.2630, dtype=torch.float64)\n",
      "train acc   tensor(0.8955)\n",
      "\n",
      "Epoch 979/999:\n",
      "train loss  tensor(0.2628, dtype=torch.float64)\n",
      "train acc   tensor(0.8955)\n",
      "\n",
      "Epoch 980/999:\n",
      "train loss  tensor(0.2627, dtype=torch.float64)\n",
      "train acc   tensor(0.8955)\n",
      "\n",
      "Epoch 981/999:\n",
      "train loss  tensor(0.2631, dtype=torch.float64)\n",
      "train acc   tensor(0.8952)\n",
      "\n",
      "Epoch 982/999:\n",
      "train loss  tensor(0.2634, dtype=torch.float64)\n",
      "train acc   tensor(0.8950)\n",
      "\n",
      "Epoch 983/999:\n",
      "train loss  tensor(0.2636, dtype=torch.float64)\n",
      "train acc   tensor(0.8947)\n",
      "\n",
      "Epoch 984/999:\n",
      "train loss  tensor(0.2633, dtype=torch.float64)\n",
      "train acc   tensor(0.8950)\n",
      "\n",
      "Epoch 985/999:\n",
      "train loss  tensor(0.2635, dtype=torch.float64)\n",
      "train acc   tensor(0.8952)\n",
      "\n",
      "Epoch 986/999:\n",
      "train loss  tensor(0.2635, dtype=torch.float64)\n",
      "train acc   tensor(0.8950)\n",
      "\n",
      "Epoch 987/999:\n",
      "train loss  tensor(0.2635, dtype=torch.float64)\n",
      "train acc   tensor(0.8950)\n",
      "\n",
      "Epoch 988/999:\n",
      "train loss  tensor(0.2634, dtype=torch.float64)\n",
      "train acc   tensor(0.8947)\n",
      "\n",
      "Epoch 989/999:\n",
      "train loss  tensor(0.2627, dtype=torch.float64)\n",
      "train acc   tensor(0.8950)\n",
      "\n",
      "Epoch 990/999:\n",
      "train loss  tensor(0.2633, dtype=torch.float64)\n",
      "train acc   tensor(0.8923)\n",
      "\n",
      "Epoch 991/999:\n",
      "train loss  tensor(0.2626, dtype=torch.float64)\n",
      "train acc   tensor(0.8955)\n",
      "\n",
      "Epoch 992/999:\n",
      "train loss  tensor(0.2623, dtype=torch.float64)\n",
      "train acc   tensor(0.8950)\n",
      "\n",
      "Epoch 993/999:\n",
      "train loss  tensor(0.2620, dtype=torch.float64)\n",
      "train acc   tensor(0.8964)\n",
      "\n",
      "Epoch 994/999:\n",
      "train loss  tensor(0.2621, dtype=torch.float64)\n",
      "train acc   tensor(0.8958)\n",
      "\n",
      "Epoch 995/999:\n",
      "train loss  tensor(0.2620, dtype=torch.float64)\n",
      "train acc   tensor(0.8952)\n",
      "\n",
      "Epoch 996/999:\n",
      "train loss  tensor(0.2618, dtype=torch.float64)\n",
      "train acc   tensor(0.8952)\n",
      "\n",
      "Epoch 997/999:\n",
      "train loss  tensor(0.2617, dtype=torch.float64)\n",
      "train acc   tensor(0.8952)\n",
      "\n",
      "Epoch 998/999:\n",
      "train loss  tensor(0.2617, dtype=torch.float64)\n",
      "train acc   tensor(0.8952)\n",
      "\n",
      "Epoch 999/999:\n",
      "train loss  tensor(0.2614, dtype=torch.float64)\n",
      "train acc   tensor(0.8950)\n"
     ]
    }
   ],
   "source": [
    "model=API_net().double()\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "loss=torch.nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer,\n",
    "                                step_size=step_size,\n",
    "                                gamma=gamma)\n",
    "    \n",
    "train_accuracy_history=[]\n",
    "train_loss_history=[]\n",
    "test_accuracy_history=[]\n",
    "test_loss_history=[]\n",
    "    \n",
    "for epoch in range(num_epoch):\n",
    "    print()\n",
    "    print('Epoch {}/{}:'.format(epoch, num_epoch - 1), flush=True)\n",
    "        \n",
    "    for phase in ['train','test']:\n",
    "        if phase=='train':\n",
    "            running_loss = 0\n",
    "            running_acc = 0\n",
    "            order=np.random.permutation(len(X_train))\n",
    "            for start_index in range(0,len(X_train),batch_size):\n",
    "                optimizer.zero_grad()\n",
    "                net.train()\n",
    "                batch_indexes=order[start_index:start_index+batch_size]\n",
    "                X_batch=X_train[batch_indexes].to(device)\n",
    "                y_batch=y_train[batch_indexes].to(device)\n",
    "                preds=model.forward(X_batch)\n",
    "                loss_value=loss(preds,y_batch)\n",
    "                preds_class=preds.argmax(dim=1)\n",
    "                loss_value.backward()\n",
    "                optimizer.step()\n",
    "                running_loss+=loss_value.data.cpu()\n",
    "                running_acc+=(preds_class==y_batch).float().mean().data.cpu()\n",
    "            train_accuracy_history.append(running_acc/(len(X_train)/batch_size))\n",
    "            train_loss_history.append(running_loss/(len(X_train)/batch_size))\n",
    "        else:\n",
    "            continue\n",
    "            net.eval()\n",
    "#             preds=model.forward(X_test)\n",
    "#             loss_value=loss(preds,y_test).data\n",
    "#             preds_class=preds.argmax(dim=1)\n",
    "#             test_accuracy_history.append((preds_class==y_test).float().mean().data)\n",
    "#             test_loss_history.append(loss_value)\n",
    "    print('train loss ',train_loss_history[-1])\n",
    "    print('train acc  ',train_accuracy_history[-1])\n",
    "#     print('test loss  ',test_loss_history[-1])\n",
    "#     print('test acc   ',test_accuracy_history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "history=[train_accuracy_history,train_loss_history,test_accuracy_history,test_loss_history]\n",
    "titles = ['Train Accuracy', 'Train Loss', 'Val Accuracy', 'Val Loss']\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, image in enumerate(history):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.title(titles[i])\n",
    "    plt.grid()\n",
    "    if i == 0 or i == 1:\n",
    "        color = 'b'\n",
    "    else:\n",
    "        color = 'orange'\n",
    "    plt.plot(image,c=color, label= 'mean: %.2f' % np.array(image).mean())\n",
    "    plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Рисуем совмещенные графики  Accuracy и Loss для Тренеровочной и валидационной выборки\n",
    "titles_ = ['Accuracy','Loss']\n",
    "plt.figure(figsize=(10, 5))\n",
    "k=0\n",
    "for i in range(2):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.plot(history[0+k], label='Tain', c='b')\n",
    "    plt.plot(history[2+k], label='Val', c='orange')\n",
    "    plt.title(titles_[i])\n",
    "    plt.grid()\n",
    "    plt.legend(loc='best')\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43297993, 0.56702007],\n",
       "       [0.97427269, 0.02572731],\n",
       "       [0.8224569 , 0.1775431 ],\n",
       "       ...,\n",
       "       [0.93829369, 0.06170631],\n",
       "       [0.78698815, 0.21301185],\n",
       "       [0.94129553, 0.05870447]])"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=model.forward(X_test)\n",
    "m = torch.nn.Softmax(dim=1)\n",
    "y_predicted=m(preds)\n",
    "y_predicted=y_predicted.detach().numpy()\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.67020071e-01, 2.57273090e-02, 1.77543098e-01, 3.89191289e-02,\n",
       "       2.39270239e-01, 8.60470930e-01, 4.71051598e-03, 1.76966397e-01,\n",
       "       2.03487493e-01, 9.26127060e-01, 2.44690484e-02, 9.79930008e-01,\n",
       "       4.52866182e-01, 8.22211615e-01, 2.25342178e-01, 4.36889306e-03,\n",
       "       9.66143002e-01, 2.39270239e-01, 2.45097827e-01, 2.25300942e-01,\n",
       "       3.11695041e-02, 2.98895055e-02, 2.39270239e-01, 2.39270239e-01,\n",
       "       2.27033573e-01, 9.66143002e-01, 2.57273090e-02, 2.38473509e-01,\n",
       "       1.76966397e-01, 2.15628278e-01, 2.39270239e-01, 6.89602753e-02,\n",
       "       2.57273090e-02, 2.60319085e-01, 2.39270239e-01, 1.76966397e-01,\n",
       "       3.09516882e-01, 8.26568088e-02, 3.78664671e-01, 9.91548783e-01,\n",
       "       5.01256360e-01, 2.92490143e-02, 9.66143002e-01, 3.33234324e-02,\n",
       "       8.10059966e-01, 5.70350446e-01, 5.64678512e-01, 7.79346534e-01,\n",
       "       1.54329631e-01, 9.79930008e-01, 3.11695041e-02, 3.95293421e-02,\n",
       "       1.21659660e-01, 4.52873136e-01, 3.09516853e-01, 1.36691505e-01,\n",
       "       9.66143002e-01, 3.11695041e-02, 3.87433841e-01, 1.02813328e-01,\n",
       "       2.27036070e-01, 9.66143002e-01, 5.11566887e-03, 2.39270239e-01,\n",
       "       2.13013551e-01, 7.36115511e-02, 9.79930008e-01, 1.86327070e-01,\n",
       "       2.57273090e-02, 1.21873014e-03, 2.39270239e-01, 9.66143002e-01,\n",
       "       9.66143002e-01, 9.66143002e-01, 5.64678512e-01, 2.13012434e-01,\n",
       "       2.19140262e-02, 9.84955335e-01, 1.88426994e-01, 9.93030182e-01,\n",
       "       4.26662566e-03, 2.57273090e-02, 1.95707753e-01, 8.16321401e-02,\n",
       "       1.22236487e-01, 4.36889306e-03, 2.14270356e-01, 2.57273090e-02,\n",
       "       3.11695041e-02, 2.39270239e-01, 3.11695041e-02, 1.57320987e-01,\n",
       "       1.77543098e-01, 2.80342249e-01, 8.97177460e-02, 9.08383753e-02,\n",
       "       2.57273090e-02, 2.46182733e-02, 2.39270239e-01, 9.66143002e-01,\n",
       "       3.11695041e-02, 2.40174663e-01, 3.02838207e-02, 2.59434999e-04,\n",
       "       2.39270239e-01, 9.74544291e-01, 9.66143002e-01, 8.64829972e-01,\n",
       "       3.10522677e-02, 9.80467143e-01, 2.39270239e-01, 9.94997148e-01,\n",
       "       2.31738007e-02, 5.64678512e-01, 3.11695041e-02, 2.39270239e-01,\n",
       "       9.05032581e-01, 4.00664124e-01, 2.27264729e-01, 5.77546443e-02,\n",
       "       2.57273090e-02, 2.39270239e-01, 3.11695041e-02, 3.70308161e-02,\n",
       "       7.11619913e-01, 9.91309534e-01, 2.39270239e-01, 6.92620194e-01,\n",
       "       3.11695041e-02, 9.91309534e-01, 3.11695041e-02, 4.11710985e-02,\n",
       "       9.66143002e-01, 3.91449473e-02, 9.91309534e-01, 2.75201970e-02,\n",
       "       9.00722776e-01, 9.08383753e-02, 9.66143002e-01, 2.21459155e-01,\n",
       "       1.80141805e-01, 9.27271292e-01, 3.11695041e-02, 1.34384097e-01,\n",
       "       1.76102694e-01, 9.66143002e-01, 8.91448646e-03, 3.70308161e-02,\n",
       "       2.26979186e-01, 4.51086509e-01, 6.57715368e-02, 9.91309534e-01,\n",
       "       2.57273090e-02, 2.39270239e-01, 1.09089822e-04, 9.35530073e-01,\n",
       "       6.03837738e-02, 2.39270239e-01, 3.37594587e-01, 3.31333480e-02,\n",
       "       9.79930008e-01, 6.35271048e-03, 3.11695041e-02, 9.66143002e-01,\n",
       "       3.11695041e-02, 7.72834110e-01, 1.59382483e-01, 3.59178287e-02,\n",
       "       3.87943001e-03, 8.55880481e-01, 4.51086509e-01, 2.39270239e-01,\n",
       "       5.58469080e-01, 4.29199977e-01, 2.79223911e-04, 2.57273090e-02,\n",
       "       5.10619959e-01, 2.63101695e-02, 3.83829707e-01, 3.09516893e-01,\n",
       "       2.39270239e-01, 8.97177460e-02, 9.04950441e-01, 2.57273090e-02,\n",
       "       4.36889306e-03, 9.42320428e-01, 3.11695041e-02, 3.35626172e-02,\n",
       "       2.57273090e-02, 1.77543098e-01, 9.79930008e-01, 9.91309534e-01,\n",
       "       8.91448646e-03, 2.39270239e-01, 9.69854726e-01, 8.74404227e-01,\n",
       "       2.39270239e-01, 9.91548783e-01, 3.31333480e-02, 5.64678512e-01,\n",
       "       2.39270239e-01, 3.11695041e-02, 1.00775154e-01, 2.60393942e-02,\n",
       "       7.37617554e-02, 2.49243171e-01, 2.39270239e-01, 9.91309534e-01,\n",
       "       2.25335660e-01, 9.27271292e-01, 9.04950441e-01, 2.25344347e-01,\n",
       "       2.39270239e-01, 9.69646581e-02, 9.66143002e-01, 5.75844112e-01,\n",
       "       9.86814931e-01, 1.21179298e-01, 9.66143002e-01, 1.21161004e-01,\n",
       "       1.23365957e-02, 1.05145958e-01, 2.26978478e-01, 5.64678512e-01,\n",
       "       8.14386721e-02, 4.89085830e-02, 2.03491936e-01, 2.57273090e-02,\n",
       "       5.64678512e-01, 3.11695041e-02, 3.70308161e-02, 8.27529801e-02,\n",
       "       2.39270239e-01, 3.12472617e-01, 8.11074017e-03, 4.04821234e-01,\n",
       "       5.09988477e-02, 8.93711660e-01, 3.05897218e-01, 4.36889306e-03,\n",
       "       9.66143002e-01, 3.96017595e-02, 3.02267713e-02, 3.09702870e-01,\n",
       "       7.02196055e-01, 2.57273090e-02, 9.66143002e-01, 2.57273090e-02,\n",
       "       2.37298955e-03, 9.91548783e-01, 4.51086509e-01, 9.62087967e-01,\n",
       "       2.10015965e-02, 2.13011826e-01, 2.39270239e-01, 3.76158444e-01,\n",
       "       9.66143002e-01, 2.39270239e-01, 9.05066211e-02, 2.39270239e-01,\n",
       "       3.11695041e-02, 9.66143002e-01, 1.48656823e-01, 9.66143002e-01,\n",
       "       9.91309534e-01, 1.05809271e-01, 9.66143002e-01, 4.71051598e-03,\n",
       "       9.79930008e-01, 5.58469080e-01, 2.39270239e-01, 2.50546692e-01,\n",
       "       1.76966397e-01, 3.09630366e-03, 9.79930008e-01, 9.66143002e-01,\n",
       "       5.87044677e-02, 2.39270239e-01, 1.24704650e-01, 3.84667284e-02,\n",
       "       2.57273090e-02, 4.51086509e-01, 3.11695041e-02, 9.66143002e-01,\n",
       "       3.93990746e-02, 9.66143002e-01, 5.64678512e-01, 4.51086509e-01,\n",
       "       9.07045648e-01, 3.13625800e-01, 9.91309534e-01, 2.39270239e-01,\n",
       "       9.74474992e-01, 2.57273090e-02, 5.64678512e-01, 3.70308161e-02,\n",
       "       3.33735231e-02, 2.92490143e-02, 9.80467143e-01, 2.06098869e-02,\n",
       "       3.11695041e-02, 9.79930008e-01, 2.18236534e-01, 3.70308161e-02,\n",
       "       9.91309534e-01, 3.89459632e-02, 2.50948027e-03, 4.29199969e-01,\n",
       "       4.55905131e-01, 3.61003844e-01, 1.99075793e-02, 3.11695041e-02,\n",
       "       2.39270239e-01, 9.27271292e-01, 8.98289340e-01, 9.33602203e-02,\n",
       "       9.42320428e-01, 2.39270239e-01, 9.75794059e-01, 2.25342110e-01,\n",
       "       2.39270239e-01, 3.11695041e-02, 1.23172745e-01, 9.66143002e-01,\n",
       "       2.39270239e-01, 9.91548783e-01, 3.02660702e-02, 1.76966397e-01,\n",
       "       4.93894020e-02, 2.92490143e-02, 3.11695041e-02, 3.80008506e-01,\n",
       "       1.10990521e-01, 6.16964822e-02, 5.87044677e-02, 7.89182662e-02,\n",
       "       1.82394718e-01, 3.99164988e-02, 7.03510077e-02, 2.57273090e-02,\n",
       "       1.23171887e-01, 9.27271292e-01, 4.38502655e-03, 6.50713623e-02,\n",
       "       3.94867003e-02, 3.11695041e-02, 4.58361193e-02, 5.87044677e-02,\n",
       "       2.81062152e-02, 1.58397523e-02, 2.98895055e-02, 5.64678512e-01,\n",
       "       3.87943001e-03, 3.11695041e-02, 8.91448646e-03, 3.09516893e-01,\n",
       "       9.66143002e-01, 1.63694065e-02, 9.80467143e-01, 2.46107796e-01,\n",
       "       2.39270239e-01, 9.27271292e-01, 9.25111110e-01, 8.97177460e-02,\n",
       "       4.29200158e-01, 2.76112514e-02, 5.15286939e-02, 9.91548783e-01,\n",
       "       9.55233596e-01, 4.76411728e-03, 1.45912907e-02, 1.46733374e-02,\n",
       "       9.91548783e-01, 2.19432795e-01, 2.05903293e-01, 1.36691505e-01,\n",
       "       9.84955335e-01, 4.52873017e-01, 2.74512088e-02, 1.54585614e-01,\n",
       "       3.41748914e-02, 9.66143002e-01, 5.64678512e-01, 2.54591547e-01,\n",
       "       9.75794059e-01, 4.51086509e-01, 1.85425991e-01, 2.39270239e-01,\n",
       "       2.30022852e-03, 9.69854726e-01, 9.66143002e-01, 3.15745519e-01,\n",
       "       2.39270239e-01, 9.66143002e-01, 9.36265423e-01, 3.80836159e-01,\n",
       "       2.39270239e-01, 1.10676128e-02, 9.66143002e-01, 2.39270239e-01,\n",
       "       2.39270239e-01, 5.34254540e-02, 2.57273090e-02, 5.25496683e-01,\n",
       "       9.66143002e-01, 2.41003018e-02, 9.66143002e-01, 4.51086509e-01,\n",
       "       9.66143002e-01, 9.66143002e-01, 2.39270239e-01, 1.18622574e-01,\n",
       "       4.29199960e-01, 2.32761215e-01, 1.89656350e-03, 9.66143002e-01,\n",
       "       1.76966397e-01, 3.43244725e-02, 2.39270239e-01, 9.66143002e-01,\n",
       "       9.66143002e-01, 3.81494360e-01, 5.87082627e-02, 1.57319057e-02,\n",
       "       8.91448646e-03, 5.64678512e-01, 2.54591548e-01, 1.29226259e-01,\n",
       "       8.97177460e-02, 5.31303629e-01, 2.39270239e-01, 2.57273090e-02,\n",
       "       1.91532059e-02, 9.66143002e-01, 3.11695041e-02, 4.13737701e-02,\n",
       "       2.39270239e-01, 2.39270239e-01, 9.66143002e-01, 3.11695041e-02,\n",
       "       2.57273090e-02, 4.16162840e-01, 2.40181123e-01, 5.09582562e-03,\n",
       "       3.38829257e-01, 5.46556134e-02, 2.74734832e-01, 8.98468279e-01,\n",
       "       9.93030182e-01, 5.92307410e-02, 3.33735231e-02, 4.05138441e-01,\n",
       "       8.91448646e-03, 5.06530246e-02, 5.67473035e-02, 2.75201970e-02,\n",
       "       9.79930008e-01, 8.91448646e-03, 1.54017572e-03, 9.66143002e-01,\n",
       "       2.39270239e-01, 2.39270239e-01, 9.42320428e-01, 9.66143002e-01,\n",
       "       1.67261312e-02, 2.57273090e-02, 3.11695041e-02, 3.11695041e-02,\n",
       "       3.11695041e-02, 7.60085968e-01, 4.51086509e-01, 1.28455542e-01,\n",
       "       2.39270239e-01, 2.13011841e-01, 4.47423282e-02, 3.86430535e-02,\n",
       "       1.57833271e-01, 6.52516057e-01, 2.39270239e-01, 3.09516893e-01,\n",
       "       9.66143002e-01, 7.03510077e-02, 9.91309534e-01, 8.95541221e-01,\n",
       "       9.79930008e-01, 2.86978480e-03, 9.66143002e-01, 3.09516893e-01,\n",
       "       4.29398373e-01, 3.39261989e-03, 5.12925760e-01, 2.39270239e-01,\n",
       "       4.55905147e-01, 4.36283092e-01, 5.87044677e-02, 7.03510077e-02,\n",
       "       2.92490143e-02, 1.76391159e-02, 9.18330255e-01, 5.55251733e-02,\n",
       "       2.98895055e-02, 3.09516760e-01, 2.05854093e-03, 3.11695041e-02,\n",
       "       7.03510077e-02, 3.11695041e-02, 2.25338451e-01, 2.39270239e-01,\n",
       "       2.92555390e-01, 9.66143002e-01, 2.98895055e-02, 5.83140821e-01,\n",
       "       3.75751636e-02, 2.39270239e-01, 2.57273090e-02, 5.92236577e-02,\n",
       "       3.11695041e-02, 4.05142055e-01, 2.57273090e-02, 2.57273090e-02,\n",
       "       4.29199854e-01, 2.39270239e-01, 8.35281000e-02, 9.18330255e-01,\n",
       "       9.18330255e-01, 9.66143002e-01, 2.25447011e-01, 9.66143002e-01,\n",
       "       8.21412353e-02, 3.11695041e-02, 8.79185839e-02, 3.97180490e-03,\n",
       "       4.14878273e-01, 5.64678512e-01, 2.94865938e-02, 2.34943180e-01,\n",
       "       9.66143002e-01, 1.33155245e-01, 3.58299750e-02, 9.80467143e-01,\n",
       "       1.62043811e-01, 1.86689902e-01, 4.81356525e-02, 2.00127909e-03,\n",
       "       2.06098869e-02, 9.66143002e-01, 1.91532059e-02, 9.79930008e-01,\n",
       "       3.40307431e-02, 7.02217208e-02, 3.33735231e-02, 4.51086509e-01,\n",
       "       1.53329242e-02, 2.39270239e-01, 9.66143002e-01, 8.91448646e-03,\n",
       "       5.41808611e-01, 7.08813754e-02, 2.15281810e-03, 9.16622794e-01,\n",
       "       4.51086509e-01, 2.39270239e-01, 9.91309534e-01, 9.66143002e-01,\n",
       "       6.09732529e-03, 2.78584910e-01, 2.39270239e-01, 1.57320987e-01,\n",
       "       2.26983550e-01, 9.66143002e-01, 2.39906025e-02, 3.00494488e-02,\n",
       "       2.39270239e-01, 2.57273090e-02, 3.11695041e-02, 2.39270239e-01,\n",
       "       1.86321765e-03, 1.65123837e-02, 9.66143002e-01, 2.13011913e-01,\n",
       "       2.25342104e-01, 7.03510077e-02, 9.30835562e-01, 2.58764436e-02,\n",
       "       4.22274815e-04, 2.39270239e-01, 2.39270239e-01, 2.39270239e-01,\n",
       "       3.31333480e-02, 2.53626129e-01, 9.66143002e-01, 5.64678512e-01,\n",
       "       9.66143002e-01, 1.46931139e-02, 3.06522251e-01, 7.68161278e-02,\n",
       "       2.57273090e-02, 2.25341845e-01, 1.02522930e-01, 4.26662566e-03,\n",
       "       2.39270239e-01, 7.95767541e-04, 3.70308161e-02, 4.16162840e-01,\n",
       "       8.56991110e-01, 2.27264729e-01, 4.21373994e-02, 3.11695041e-02,\n",
       "       9.93030182e-01, 5.45944456e-01, 2.03485737e-01, 2.97018773e-01,\n",
       "       9.66143002e-01, 2.64356399e-01, 3.87107828e-01, 1.91532059e-02,\n",
       "       1.13220622e-04, 9.80467143e-01, 1.69982703e-02, 4.55905131e-01,\n",
       "       3.33735231e-02, 9.66143002e-01, 2.39270239e-01, 1.76966397e-01,\n",
       "       2.93054865e-01, 4.51086509e-01, 3.11695041e-02, 3.06518140e-01,\n",
       "       9.79930008e-01, 4.38502655e-03, 1.12636557e-01, 9.66143002e-01,\n",
       "       2.26983394e-01, 1.05880424e-01, 2.42577308e-01, 4.71051598e-03,\n",
       "       1.23172745e-01, 2.27264729e-01, 2.98895055e-02, 5.82032999e-02,\n",
       "       2.01129968e-01, 4.26662566e-03, 3.15310447e-03, 2.39270239e-01,\n",
       "       2.21624392e-01, 9.91309534e-01, 2.25342121e-01, 4.29199854e-01,\n",
       "       3.04665441e-01, 2.39270239e-01, 3.06093484e-02, 2.45097844e-01,\n",
       "       2.39270239e-01, 7.89174308e-02, 2.45094609e-01, 2.39270239e-01,\n",
       "       2.27264729e-01, 6.35279554e-02, 9.91309534e-01, 2.57273090e-02,\n",
       "       3.96041065e-02, 1.30193287e-01, 3.06093484e-02, 2.39270239e-01,\n",
       "       9.43204366e-01, 2.27264729e-01, 9.30835562e-01, 3.11695041e-02,\n",
       "       3.11695041e-02, 9.66143002e-01, 1.30147559e-01, 2.03485708e-01,\n",
       "       2.53680451e-02, 9.93030182e-01, 9.75278134e-01, 6.95198877e-01,\n",
       "       9.66143002e-01, 9.84955335e-01, 2.13011698e-01, 2.39693198e-01,\n",
       "       3.11695041e-02, 3.11695041e-02, 2.74512088e-02, 2.57273090e-02,\n",
       "       9.91548783e-01, 3.32899088e-02, 1.77543098e-01, 4.14342246e-04,\n",
       "       5.64678512e-01, 3.11695041e-02, 5.64678512e-01, 1.69982703e-02,\n",
       "       2.21790497e-02, 9.66143002e-01, 9.66143002e-01, 9.91309534e-01,\n",
       "       3.83829707e-01, 4.17156960e-01, 9.78922891e-01, 2.39270239e-01,\n",
       "       2.13617896e-02, 9.27271292e-01, 3.87943001e-03, 1.02813328e-01,\n",
       "       8.89406984e-01, 2.57273090e-02, 9.66143002e-01, 9.91309534e-01,\n",
       "       6.09459541e-03, 9.18330255e-01, 2.57273090e-02, 7.46244213e-01,\n",
       "       1.69536326e-01, 2.57273090e-02, 9.93030182e-01, 2.25334924e-01,\n",
       "       1.06625718e-02, 9.91548783e-01, 2.39270239e-01, 2.39270239e-01,\n",
       "       7.69432781e-02, 3.09516880e-01, 2.39270239e-01, 9.66143002e-01,\n",
       "       3.11695041e-02, 2.57273090e-02, 1.13754629e-01, 2.25033527e-01,\n",
       "       4.38123714e-04, 9.16668452e-01, 2.39270239e-01, 2.57273090e-02,\n",
       "       6.32354070e-02, 5.64678512e-01, 2.57273090e-02, 2.80511899e-01,\n",
       "       4.55905137e-01, 2.39270239e-01, 3.94612572e-03, 1.80860516e-02,\n",
       "       1.69982703e-02, 3.25776095e-02, 1.29226259e-01, 7.79019747e-02,\n",
       "       9.93030182e-01, 8.45124610e-01, 2.87696814e-02, 2.27040934e-01,\n",
       "       5.34397554e-03, 1.92200117e-02, 9.93030182e-01, 2.39270239e-01,\n",
       "       9.66143002e-01, 1.52349730e-01, 9.66143002e-01, 1.92138703e-01,\n",
       "       2.57273090e-02, 2.57273090e-02, 2.73605415e-01, 5.64678512e-01,\n",
       "       2.57273090e-02, 2.98895055e-02, 5.64678512e-01, 2.39270239e-01,\n",
       "       1.77483459e-03, 3.73158576e-01, 9.66143002e-01, 3.11695041e-02,\n",
       "       3.11695041e-02, 2.77437902e-01, 9.18330255e-01, 1.15793241e-01,\n",
       "       1.97817881e-01, 9.18330255e-01, 2.48137883e-01, 1.68296555e-02,\n",
       "       3.06518188e-01, 9.66143002e-01, 6.60560084e-03, 7.16266356e-02,\n",
       "       1.35048032e-01, 9.66143002e-01, 1.05445583e-01, 1.52500661e-01,\n",
       "       9.91309534e-01, 2.45097836e-01, 4.01181122e-01, 5.87044677e-02,\n",
       "       9.97732171e-03, 9.11059604e-01, 1.57833271e-01, 9.03469857e-01,\n",
       "       2.49243184e-01, 6.41786246e-02, 2.84524793e-01, 9.25159621e-03,\n",
       "       3.11695041e-02, 9.18330255e-01, 9.80467143e-01, 9.66143002e-01,\n",
       "       5.52501577e-01, 2.92871332e-02, 8.34129680e-02, 9.91309534e-01,\n",
       "       4.38502655e-03, 2.27264729e-01, 9.91309534e-01, 9.66143002e-01,\n",
       "       7.13557335e-02, 4.26662566e-03, 1.74010730e-01, 8.91448646e-03,\n",
       "       3.09516891e-01, 2.57273090e-02, 3.11695041e-02, 2.25342151e-01,\n",
       "       5.64678512e-01, 2.06098869e-02, 3.11695041e-02, 3.11695041e-02,\n",
       "       2.57273090e-02, 7.79618310e-02, 2.57273090e-02, 4.16162840e-01,\n",
       "       1.55902059e-02, 2.51352741e-04, 5.58646515e-03, 2.57273090e-02,\n",
       "       3.53076240e-01, 1.75527658e-01, 4.26662566e-03, 3.06518445e-01,\n",
       "       1.23172745e-01, 9.91309534e-01, 2.57273090e-02, 9.66143002e-01,\n",
       "       1.97889498e-01, 9.91309534e-01, 9.66143002e-01, 9.66143002e-01,\n",
       "       3.11695041e-02, 5.57395144e-01, 1.17590195e-01, 2.57273090e-02,\n",
       "       9.80467143e-01, 2.25342133e-01, 9.66143002e-01, 9.66143002e-01,\n",
       "       2.06098869e-02, 6.17063074e-02, 2.13011850e-01, 5.87044677e-02])"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9323, -0.0439],\n",
       "        [ 2.0322, -1.5767],\n",
       "        [ 0.3790, -1.0711],\n",
       "        ...,\n",
       "        [ 0.5776, -0.2262],\n",
       "        [ 0.8270, -1.1691],\n",
       "        [ 0.8435, -1.0464]], dtype=torch.float64, grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_predicted[:,1])\n",
    "roc_auc= auc(fpr, tpr)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
